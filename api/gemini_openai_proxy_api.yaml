openapi: 3.0.0
info:
  title: Gemini API (OpenAI Proxy)
  version: 1.0.0
  description: An OpenAPI specification for interacting with the Gemini API through an OpenAI-compatible interface.
    This API leverages Gemini's advanced capabilities, including "thinking budget" and streaming,
    while maintaining a familiar OpenAI request structure.
servers:
  - url: https://generativelanguage.googleapis.com/v1beta/openai
    description: Gemini API OpenAI-compatible endpoint
security:
  - BearerAuth: []
paths:
  /chat/completions:
    post:
      summary: Generate chat completions using Gemini models.
      operationId: createChatCompletion
      description: |
        Creates a model response for the given chat conversation.
        This endpoint supports various Gemini-specific features like `reasoning_effort` and `thinking_config`
        within an `extra_body` for fine-grained control over model behavior, as well as streaming responses.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
            examples:
              simple_prompt:
                summary: Simple chat completion
                value:
                  model: gemini-2.0-flash
                  messages:
                    - role: user
                      content: "Explain to me how AI works"
              with_reasoning_effort:
                summary: Chat completion with reasoning effort
                value:
                  model: gemini-2.5-flash
                  reasoning_effort: low
                  messages:
                    - role: user
                      content: "Describe the philosophical implications of consciousness in AI, based on the provided text."
              with_thinking_config:
                summary: Chat completion with thinking configuration
                value:
                  model: gemini-2.5-flash
                  messages:
                    - role: user
                      content: "Elaborate on the most badass features of advanced AI based on the attached document."
                  extra_body:
                    google:
                      thinking_config:
                        include_thoughts: true
              streaming_response:
                summary: Streaming chat completion
                value:
                  model: gemini-2.0-flash
                  messages:
                    - role: user
                      content: "Describe the future of quantum computing in a streaming fashion, incorporating novel abilities not yet widely known."
                  stream: true
      responses:
        '200':
          description: Successful response containing chat completion results.
          content:
            application/json:
              schema:
                oneOf:
                  - $ref: '#/components/schemas/ChatCompletionResponse'
                  - $ref: '#/components/schemas/StreamedChatCompletionChunk'
              examples:
                non_streaming_success:
                  summary: Non-streaming response
                  value:
                    id: chatcmpl-randomid123
                    object: chat.completion
                    created: 1678886400
                    model: gemini-2.0-flash
                    choices:
                      - index: 0
                        message:
                          role: assistant
                          content: "Artificial intelligence (AI) works by teaching computers to learn from data, make decisions, and solve problems, much like humans do. It involves various techniques like machine learning, neural networks, and deep learning..."
                        finish_reason: stop
                streaming_chunk_success:
                  summary: Streaming response chunk
                  value:
                    id: chatcmpl-streamid456
                    object: chat.completion.chunk
                    created: 1678886401
                    model: gemini-2.0-flash
                    choices:
                      - index: 0
                        delta:
                          content: "Artificial intelligence (AI) works by teaching computers..."
                        finish_reason: null
        '400':
          description: Bad Request - Invalid input or parameters.
        '401':
          description: Unauthorized - Missing or invalid API key.
        '500':
          description: Internal Server Error.

components:
  schemas:
    Message:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          description: The role of the author of this message.
          enum: [user, assistant]
        content:
          type: string
          description: The content of the message.
    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: ID of the model to use.
          examples: ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-2.5-pro"]
        messages:
          type: array
          description: A list of messages comprising the conversation so far.
          items:
            $ref: '#/components/schemas/Message'
        reasoning_effort:
          type: string
          description: |
            (Gemini-specific) Controls how much the model will "think" through complex problems.
            Note: Cannot be used with `extra_body.google.thinking_config`. Not all models support "none".
          enum: [low, medium, high, none]
          default: medium
        extra_body:
          type: object
          description: |
            (Gemini-specific) Allows for including additional Google-specific fields in the request.
            Currently supports `thinking_config` for detailed control over thought generation.
            Note: Cannot be used with `reasoning_effort`.
          properties:
            google:
              type: object
              properties:
                thinking_config:
                  type: object
                  properties:
                    include_thoughts:
                      type: boolean
                      description: |
                        Whether to include thought summaries in the response.
                        Set to `true` to receive detailed thought processes from the model.
                      default: false
                    thinking_budget:
                      type: integer
                      description: |
                        An exact token budget for the model's thinking process.
                        Cannot be used if `include_thoughts` is false or if `reasoning_effort` is set.
                      minimum: 1
        stream:
          type: boolean
          description: If set, partial message deltas will be sent, like in ChatGPT.
          default: false

    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
          enum: [chat.completion]
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        choices:
          type: array
          description: A list of chat completion choices generated by the model.
          items:
            type: object
            properties:
              index:
                type: integer
                description: The index of the choice in the list of choices.
              message:
                $ref: '#/components/schemas/Message'
              finish_reason:
                type: string
                description: The reason the model stopped generating tokens.
                enum: [stop, length, content_filter, tool_calls, function_call]
        usage:
          type: object
          properties:
            prompt_tokens:
              type: integer
            completion_tokens:
              type: integer
            total_tokens:
              type: integer

    StreamedChatCompletionChunk:
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion chunk.
        object:
          type: string
          description: The object type, which is always `chat.completion.chunk`.
          enum: [chat.completion.chunk]
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion chunk was created.
        model:
          type: string
          description: The model used for the chat completion chunk.
        choices:
          type: array
          description: A list of chat completion choices generated by the model.
          items:
            type: object
            properties:
              index:
                type: integer
                description: The index of the choice in the list of choices.
              delta:
                type: object
                properties:
                  role:
                    type: string
                    enum: [user, assistant]
                  content:
                    type: string
              finish_reason:
                type: string
                description: The reason the model stopped generating tokens.
                enum: [stop, length, content_filter, tool_calls, function_call]

  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT # Or other token format like 'API Key' if it's not strictly JWT. For Gemini, it's typically an API key.