#
# Flaky Test Detection Configuration
#
# This comprehensive YAML configuration file centralizes parameters and strategies
# for identifying, retrying, and managing flaky tests within a Continuous Integration (CI) pipeline.
# Its primary goal is to enhance the reliability of your test suite by distinguishing
# between genuine, consistent failures and intermittent, transient "flaky" failures.
#
# --- Key Principles ---
# 1. Automation: Reduce manual intervention by automatically retrying unstable tests.
# 2. Clarity: Provide clear signals about test health â€“ is it truly broken, or just flaky?
# 3. Customization: Allow fine-grained control over detection logic for different test types.
# 4. Actionability: Integrate with notification and reporting systems to facilitate quick follow-up.
# 5. Maintainability: Centralize configuration to avoid scattering parameters across multiple workflows.
#
# --- How to Use This File ---
# This configuration is designed to be consumed by a dedicated CI workflow script (e.g., a GitHub Action).
# The script would typically perform the following steps:
#   a. Parse this YAML file to load all defined settings and test groups.
#   b. For each test group (or `global_settings` if no group matches), determine the
#      `test_command_prefix`, `test_path_pattern`, `max_retries`, `retry_delay_seconds`, etc.
#   c. Execute the tests identified by the pattern, implementing the retry logic as configured.
#   d. Analyze test results for each run:
#      - If a test passes on the initial attempt, it's considered stable.
#      - If a test fails initially but passes on a subsequent retry, it's marked as "flaky".
#      - If a test fails consistently across all `max_retries` attempts, it's marked as "consistent failure".
#   e. Trigger various notifications (Slack, Email, GitHub Issues/PR Comments) and generate
#      detailed reports based on the outcomes and the settings in the `notifications` and
#      `reporting_and_integration` sections.
#   f. Potentially adjust the CI job's exit status based on the `fail_job_on_consistent_failure` setting,
#      ensuring that consistent failures block the pipeline while flaky tests might just generate alerts.
#
# --- Recommended Workflow Integration ---
# 1. Create a dedicated GitHub Actions workflow (e.g., `.github/workflows/flaky-test-runner.yml`)
#    that triggers on `push`, `pull_request`, or a `schedule` (e.g., nightly).
# 2. In this workflow, use `actions/checkout@v4` to clone your repository.
# 3. Use language-specific setup actions (e.g., `actions/setup-node@v4` for Node.js,
#    `actions/setup-python@v4` for Python) to prepare the test environment.
# 4. Add a step that utilizes a custom script (e.g., a Bash, Python, or JavaScript script)
#    to parse this `flaky-test-config.yml` file. This script will then orchestrate
#    the execution of test commands, apply retry logic, and handle result analysis.
# 5. Utilize GitHub's `secrets` feature to securely store sensitive data such as webhook URLs,
#    API keys, and email credentials, referencing them via `_secret_name` fields in this config.
# 6. Upload any generated `artifacts` (e.g., logs, reports, screenshots, videos) from the
#    `reporting_and_integration.artifacts` section for easier debugging and post-mortem analysis.
#
# --- Version History ---
# v1.0.0 (2023-10-27): Initial comprehensive configuration structure.
# v1.1.0 (2023-11-15): Added more detailed notification templates, GitHub issue options, and placeholders.
# v1.2.0 (2023-12-01): Expanded `test_groups`, `reporting_and_integration` sections, and added health checks.
#
flaky_test_detection_config:
  # General metadata and administrative information about this configuration file.
  # This section helps in managing, understanding, and documenting the purpose and version of the configuration.
  metadata:
    schema_version: "1.2.0" # Current version of the configuration schema this file adheres to.
    config_name: "Global Project Flaky Test Strategy" # A descriptive name for this configuration instance.
    last_updated: "2023-12-01" # The date when this configuration file was last modified.
    maintainers: # A list of individuals or teams responsible for maintaining this configuration file.
      - name: "CI/CD Engineering Team"
        contact_email: "ci-cd@example.com"
        github_handle: "@org/ci-cd-team"
        role: "Primary Owner"
      - name: "Quality Assurance Lead"
        contact_email: "qa-lead@example.com"
        github_handle: "@qa-lead-github"
        role: "Contributor & Stakeholder"
    description: |
      This configuration defines the default and specialized strategies for
      detecting, managing, and reporting flaky tests across various parts
      of the project's codebase. It aims to ensure a stable and reliable
      CI/CD pipeline by systematically addressing intermittent test failures.
    documentation_url: "https://docs.example.com/ci/flaky-tests-guide" # Link to external documentation.

  # Global settings apply universally to all flaky test detection runs unless
  # explicitly overridden by a more specific `test_group` definition.
  # These parameters establish the baseline behavior for the flaky test runner,
  # ensuring a consistent default approach.
  global_settings:
    # `max_retries`: The maximum number of attempts (including the initial run)
    #               to execute a test suite or a specific test pattern before
    #               declaring it as a "consistent failure" if it never passes.
    #               - A value of `1` means the test runs once; no retries are performed.
    #               - A value of `N` (where N > 1) means the test runs once initially,
    #                 and then is retried up to `N-1` additional times if it fails.
    #               Higher values increase the chance of identifying flakiness, but
    #               also extend CI execution time for problematic tests.
    max_retries: 3 # Default: 3 attempts (1 initial + 2 retries)

    # `retry_delay_seconds`: The duration (in seconds) to pause between consecutive
    #                      retry attempts after a test failure. This delay is crucial
    #                      for allowing system resources to reset, network conditions
    #                      to stabilize, or external services to recover from transient issues.
    #                      - `0`: Indicates an immediate retry with no pause.
    #                      - `>0`: Specifies a wait period for the given number of seconds.
    retry_delay_seconds: 5 # Default: 5 seconds

    # `test_command_prefix`: The base command responsible for invoking your test runner.
    #                      This string will be used as the foundation upon which test
    #                      patterns and other arguments are dynamically appended by the CI script.
    #                      Ensure it correctly activates your test framework (e.g., Jest, Mocha,
    #                      Playwright, Cypress) and includes any necessary flags like `--` to separate
    #                      test runner arguments from the command itself.
    #                      Examples: "npm test --", "yarn cypress run --", "pnpm jest --"
    test_command_prefix: "npm test --" # Default: Standard npm test command

    # `default_test_path_pattern`: A regular expression or glob pattern that identifies
    #                            the set of tests considered for flaky detection by default.
    #                            This pattern is passed as an argument to your `test_command_prefix`
    #                            (e.g., `--testPathPattern` for Jest, `--grep` for Mocha, or a glob for Cypress).
    #                            This default pattern is applied when no specific `test_group` matches.
    #                            Example: ".*\\.flaky\\.js|tests/e2e/.*\\.cy\\.ts|components/.*/__tests__/.*\\.spec\\.tsx"
    default_test_path_pattern: ".*\\.flaky\\.test\\.js|.*\\.intermittent\\.spec\\.ts|tests/(flaky|unstable|intermittent)/.*\\.(js|ts|jsx|tsx|vue)"

    # `fail_job_on_consistent_failure`: A boolean flag that dictates the CI workflow's behavior
    #                                 if a test consistently fails across all `max_retries` attempts
    #                                 (i.e., it never passes).
    #                                 - `true`: The CI job/workflow step will explicitly fail, signaling a
    #                                           critical, persistent issue that needs immediate attention and blocking progression.
    #                                 - `false`: The CI job/workflow will continue to pass, even if tests
    #                                            consistently fail. Notifications will still be sent,
    #                                            but the pipeline won't be blocked. This is sometimes used for
    #                                            non-critical tests where a failure shouldn't halt the entire pipeline.
    fail_job_on_consistent_failure: true # Default: true (block the pipeline for consistent failures)

    # `verbose_logging`: If set to `true`, the CI script executing the tests will
    #                  output more detailed information about each retry attempt. This includes
    #                  the exact commands executed, their exit codes, and raw stdout/stderr streams.
    #                  This increased verbosity is invaluable for debugging the flaky detection
    #                  process itself and understanding the specific context of test failures.
    verbose_logging: true # Default: true

    # `report_output_path`: The file path within the CI workspace where a comprehensive
    #                     summary report of the flaky test detection run should be generated.
    #                     This report can be in various formats (e.g., JSON, XML) and
    #                     typically includes: a list of tests detected as flaky (passed on retry),
    #                     a list of tests that consistently failed, and overall run statistics.
    #                     This generated file is often uploaded as a GitHub Actions artifact for later review.
    report_output_path: "flaky-test-artifacts/global_flaky_report.json"

    # `environment_variables`: A list of key-value pairs representing environment variables
    #                        to set specifically for the execution of flaky tests. This allows for
    #                        runtime adjustments to your application or test environment,
    #                        such as enabling specific debug modes, adjusting logging levels,
    #                        or modifying test environment behavior to aid in diagnosis.
    environment_variables:
      - name: "NODE_ENV"
        value: "test"
        description: "Standard environment for test runs."
      - name: "FLAKY_DETECTION_ACTIVE"
        value: "true"
        description: "Flag to inform test code that it's running in a flaky detection context, potentially triggering special logic."
      - name: "LOG_LEVEL"
        value: "debug"
        description: "Increase logging verbosity within the application under test during flaky runs to capture more details."
      - name: "EXTERNAL_API_TIMEOUT_MS"
        value: "15000"
        description: "Potentially increase API timeouts (in milliseconds) to reduce network-related flakiness with external services."
      - name: "CI_RUNNER_ID"
        value: "{{github_run_id}}"
        description: "Inject GitHub run ID for traceability in application/test logs."

  # Configuration for various notification channels to alert relevant teams
  # about flaky test events. This includes tests detected as flaky (passed on retry)
  # and tests that consistently fail after all retries.
  notifications:
    # `enabled`: Master switch to globally enable or disable all notification types
    #            configured within this `notifications` section.
    enabled: true

    # Slack channel notifications.
    slack:
      enabled: true # Enable/disable Slack notifications
      # `webhook_url_secret_name`: The name of the GitHub secret that stores the Slack
      #                            incoming webhook URL. Storing this as a secret is
      #                            a crucial security best practice.
      webhook_url_secret_name: "SLACK_WEBHOOK_FLAKY_TESTS"
      # `channel`: The Slack channel ID or name (e.g., "#dev-alerts", "@username")
      #            where notifications will be posted.
      channel: "#ci-test-alerts"
      # `username`: The display name of the bot that will post the messages in Slack.
      username: "FlakyTestMonitor"
      # `icon_emoji`: An emoji string (e.g., ":robot_face:") to use as the bot's icon in Slack.
      icon_emoji: ":robot_face:"

      # `flaky_message_template`: Markdown-formatted template for messages sent when
      #                         a test is detected as flaky (initially failed, then passed on retry).
      #                         Available placeholders: `{{test_pattern}}`, `{{attempts_successful}}`,
      #                         `{{total_attempts}}`, `{{repo}}`, `{{branch}}`, `{{workflow_url}}`,
      #                         `{{sha}}`, `{{run_number}}`, `{{github_actor}}`.
      flaky_message_template: |
        :warning: *Flaky Test Detected!*
        *Repo:* `{{repo}}` / *Branch:* `{{branch}}`
        *Test Pattern:* `{{test_pattern}}`
        *Status:* :white_check_mark: Passed on attempt *{{attempts_successful}}* / *{{total_attempts}}*.
        *Investigate:* <{{workflow_url}}|Workflow Run #{{run_number}}>
        *Commit:* `{{sha}}` (Triggered by: `{{github_actor}}`)
        ---
        _This test has shown intermittent behavior. Please consider investigating its stability._

      # `consistent_failure_message_template`: Markdown-formatted template for messages sent when
      #                                      a test consistently fails even after all `max_retries` attempts.
      #                                      Uses the same placeholders as `flaky_message_template`.
      consistent_failure_message_template: |
        :x: *Critical: Consistent Test Failure After Retries!*
        *Repo:* `{{repo}}` / *Branch:* `{{branch}}`
        *Test Pattern:* `{{test_pattern}}`
        *Status:* :red_circle: Failed consistently after *{{total_attempts}}* attempts.
        *Action Required*: <{{workflow_url}}|Workflow Run #{{run_number}}>
        *Commit:* `{{sha}}` (Triggered by: `{{github_actor}}`)
        ---
        _This test is persistently failing and requires immediate attention. It indicates a genuine bug, not just flakiness._

      # `send_summary_message`: If true, a summary message will be sent to Slack
      #                         at the very end of the entire flaky detection workflow run,
      #                         providing an overview of all tests processed.
      send_summary_message: true
      summary_message_template: |
        :loudspeaker: *Flaky Test Detection Run Summary for {{repo}}/{{branch}}*
        *Total tests analyzed:* {{total_tests_analyzed}}
        *Detected as flaky:* {{flaky_count}} (:warning:)
        *Consistently failed:* {{consistent_failure_count}} (:x:)
        [View Full Report]({{report_url}}) | [Workflow Logs]({{workflow_url}})
        ---
        _This summary reflects the overall outcome of the flaky test run, triggered by `{{github_actor}}`._

    # Email notifications. Requires an underlying GitHub Action or script capable of sending emails
    # (e.g., using SendGrid, Mailgun, or a custom SMTP configuration).
    email:
      enabled: false # Set to true to enable email notifications
      # `recipients`: Comma-separated list of email addresses to send notifications to.
      recipients: "dev-team@example.com,qa-leads@example.com,on-call@example.com"
      # `sender`: The email address from which notifications will be sent (e.g., "ci-notifier@yourdomain.com").
      sender: "ci-notifier@yourdomain.com"
      # `subject_template`: Template for the email subject line. `{{status_label}}` will be "Flaky" or "Consistent Failure".
      subject_template: "[CI/CD Alert] {{repo}}/{{branch}} - Flaky Test Status: {{status_label}}"
      # `body_template`: Template for the email body. This can be plain text or HTML.
      body_template: |
        Hello Team,
        
        This is an automated alert from your CI/CD system regarding test stability.
        
        Repository: {{repo}}
        Branch: {{branch}}
        Commit SHA: {{sha}}
        Workflow Run: {{workflow_url}} (Run #{{run_number}})
        Triggered by: {{github_actor}}
        
        Test Pattern: "{{test_pattern}}"
        Status: {{status_description}} (Passed on attempt {{attempts_successful}} / {{total_attempts}}).
        
        Details:
        {{detailed_report_link}}
        
        {{conditional_message_suffix}}
        
        Please investigate the root cause of this behavior.
        
        Best regards,
        Your CI/CD System
      # `on_flaky_detection_template_suffix`: Specific message to append to the email body
      #                                     when a test is detected as flaky.
      on_flaky_detection_template_suffix: "This test passed intermittently. Focus on identifying and resolving the root cause of its unreliability rather than suppressing it."
      # `on_consistent_failure_template_suffix`: Specific message to append to the email body
      #                                        when a test consistently fails across all retries.
      on_consistent_failure_template_suffix: "This test consistently failed across all retries. It indicates a critical, blocking issue requiring immediate fix and not just flakiness."

    # GitHub-specific notifications (creation of issues, comments on pull requests).
    # This leverages the GitHub API for direct integration with your repository.
    github:
      # `create_issue_on_flaky_detection`: If true, a new GitHub issue will be created
      #                                   when a test is detected as flaky (passed on retry).
      create_issue_on_flaky_detection: true
      # `issue_labels`: A list of labels (strings) to apply to any newly created GitHub issue.
      issue_labels:
        - "bug"
        - "flaky-test"
        - "investigate"
        - "priority:medium"
        - "automation"
      # `issue_assignees`: A list of GitHub usernames to assign to any newly created issue.
      issue_assignees:
        - "github-username-1"
        - "github-username-2"
      # `issue_title_template`: Template for the title of the GitHub issue.
      issue_title_template: "[Flaky Test] `{{test_pattern}}` in `{{repo}}` (Branch: `{{branch}}`)"
      # `issue_body_template`: Template for the body of the GitHub issue. Supports Markdown formatting.
      issue_body_template: |
        A test matching the pattern `{{test_pattern}}` has exhibited flaky behavior in the CI pipeline.
        
        **Details:**
        - Repository: `{{repo}}`
        - Branch: `{{branch}}`
        - Commit SHA: `{{sha}}`
        - Workflow Run: [Link to Workflow Run #{{run_number}}]({{workflow_url}})
        - Test Status: Succeeded on attempt {{attempts_successful}} out of {{total_attempts}} retries.
        - Triggered by: `{{github_actor}}`
        
        **Impact:** Flakiness can lead to unreliable CI signals, missed regressions, and developer frustration due to red herring failures.
        
        **Recommended Investigation Steps:**
        1. Review the test code for potential race conditions, implicit dependencies, or reliance on unreliable external factors.
        2. Examine the CI runner logs and any generated artifacts (screenshots, videos) from the failed attempts.
        3. Check for recent changes in the `{{test_pattern}}` area or in components it interacts with.
        4. Consider running the test locally multiple times to reproduce the flakiness outside of CI.
        
        Please investigate this intermittent failure and work towards a stable test.

      # `comment_on_pr_on_flaky_detection`: If true, a comment will be added to the pull request
      #                                    that triggered the workflow (if applicable) when a
      #                                    flaky test is detected within the scope of that PR's changes.
      comment_on_pr_on_flaky_detection: false
      # `pr_comment_template`: Template for the PR comment.
      pr_comment_template: |
        :warning: **Flaky Test Detected in this PR's scope!**
        A test (`{{test_pattern}}`) related to changes in this pull request exhibited flaky behavior.
        It passed on attempt {{attempts_successful}} out of {{total_attempts}} retries.
        Please be aware that this might indicate an underlying instability that could affect future merges.
        [Workflow Details]({{workflow_url}}) | [Commit]({{commit_url}})
        
      # `create_issue_on_consistent_failure`: If true, a GitHub issue will be created for tests
      #                                       that consistently fail across all retries.
      create_issue_on_consistent_failure: true
      # `consistent_failure_issue_title_template`: Title template for consistent failure issues.
      consistent_failure_issue_title_template: ":fire: Critical: Consistent Test Failure - `{{test_pattern}}` in `{{repo}}` (Branch: `{{branch}}`)"
      # `consistent_failure_issue_body_template`: Body template for consistent failure issues.
      consistent_failure_issue_body_template: |
        :fire: **Critical Alert: Consistent Test Failure Detected!** :fire:
        
        The test pattern `{{test_pattern}}` consistently failed even after {{total_attempts}} retries in the CI pipeline.
        This indicates a severe and persistent issue that is *not* just flakiness.
        
        **Details:**
        - Repository: `{{repo}}`
        - Branch: `{{branch}}`
        - Commit SHA: `{{sha}}`
        - Workflow Run: [Link to Workflow Run #{{run_number}}]({{workflow_url}})
        - Test Status: Failed all {{total_attempts}} attempts.
        - Triggered by: `{{github_actor}}`
        
        **Immediate Action Required:** This failure is critical and likely blocking deployments or releases.
        Please investigate the root cause, which might be a breaking change, a critical environment issue, or a fundamental test flaw.
        Assignees: {{issue_assignees | join(", ")}}
        Labels: {{issue_labels | join(", ")}}

  # --- Test Groups (Override Global Settings for Specific Test Sets) ---
  #
  # This section provides the ability to define distinct "test groups," each with its
  # own set of flaky detection parameters. This is invaluable for applying different
  # strategies to different types of tests (e.g., unit, integration, UI, performance)
  # or to known problematic areas of your codebase that require specialized handling.
  #
  # The runner script should iterate through these groups. If a test matches
  # a `test_path_pattern` of a group, that group's settings (and its overrides)
  # will be applied instead of the `global_settings`. The first matching group
  # in the list should typically take precedence.
  #
  test_groups:
    - name: "API-Service-Integration-Tests"
      description: |
        Configuration for API integration tests. These tests often interact with
        external microservices or databases, making them susceptible to network
        latency, service availability, and timing issues. They usually benefit from
        more retries and longer delays.
      enabled: true # Whether this specific test group is active.
      
      # Overrides specific settings from `global_settings` for this test group:
      max_retries: 5 # More retries for API calls due to higher external dependencies.
      retry_delay_seconds: 10 # Longer delay to allow external services to cool down or restart.
      test_command_prefix: "npm run test:api --" # Specific script/command for API tests.
      test_path_pattern: "tests/api/integration/.*\\.spec\\.js|tests/services/.*\\.test\\.ts" # Specific pattern for API tests.
      fail_job_on_consistent_failure: true # API failures are critical, so consistently failing should fail the job.

      # Notification overrides for this specific group:
      notifications:
        slack:
          channel: "#api-alerts-critical" # Dedicated Slack channel for API issues.
          icon_emoji: ":rocket:"
          flaky_message_template: |
            :zap: *API Flakiness Alert!* :zap:
            Test: `{{test_pattern}}` passed on attempt {{attempts_successful}}/{{total_attempts}} (Repo: `{{repo}}`, Branch: `{{branch}}`).
            [Workflow]({{workflow_url}})
        github:
          issue_labels: ["api-bug", "flaky-api-test", "P1", "service:backend"] # Higher priority for API issues.
          issue_assignees: ["@api-team-lead", "@backend-dev"]
          create_issue_on_flaky_detection: true # Always create issues for API flakiness.

    - name: "UI-EndToEnd-CriticalFlows"
      description: |
        Settings for critical user interface end-to-end tests. These are typically
        run with tools like Cypress or Playwright and are highly sensitive to
        rendering times, network delays, and browser inconsistencies.
      enabled: true
      max_retries: 4
      retry_delay_seconds: 7
      test_command_prefix: "cypress run --env CI=true --headless --browser chrome" # Cypress for UI.
      test_path_pattern: "cypress/e2e/critical-paths/.*\\.cy\\.js"
      fail_job_on_consistent_failure: true # Critical UI flows must fail the build.

      notifications:
        email:
          enabled: true
          recipients: "ui-team@example.com,product-owner@example.com"
          subject_template: "[CRITICAL UI FLAKINESS] {{repo}} - {{test_pattern}}"
        slack:
          channel: "#ui-e2e-alerts"
          username: "UI Flaky Watcher"
          icon_emoji: ":computer:"
        github:
          issue_labels: ["ui-bug", "e2e-test", "critical-path", "flaky-ui"]
          issue_assignees: ["@frontend-lead"]
          create_issue_on_flaky_detection: true
          comment_on_pr_on_flaky_detection: true # Inform PR authors immediately about UI flakiness.

    - name: "Database-Migration-Tests"
      description: |
        Tests specifically targeting database migrations and schema changes. These
        can be flaky due to complex setup/teardown, race conditions in test data,
        or transient database connection issues.
      enabled: false # This group is disabled by default and needs to be manually enabled.
      max_retries: 2
      retry_delay_seconds: 15 # Allow more time for DB connections/state to reset before retrying.
      test_command_prefix: "npm run test:db-migrations --"
      test_path_pattern: "tests/database/migrations/.*\\.test\\.js"
      fail_job_on_consistent_failure: true # Database issues are usually critical.

      notifications:
        slack:
          channel: "#db-dev-alerts"
          username: "DB Migration Bot"
          icon_emoji: ":gear:"
        github:
          create_issue_on_flaky_detection: false # Only create GitHub issues for consistent failures, not just flakiness.
          create_issue_on_consistent_failure: true

    - name: "Performance-Baseline-Tests"
      description: |
        Tests used to establish performance baselines. Minor environmental fluctuations
        or network latency can cause these to appear flaky. Flakiness here might
        indicate real performance regressions or environmental noise.
      enabled: true
      max_retries: 2 # Fewer retries for performance tests as consistent flakiness could be a real issue.
      retry_delay_seconds: 20 # Longer delays between runs to minimize transient system load.
      test_command_prefix: "npm run test:performance -- --suite=baseline"
      test_path_pattern: "tests/performance/.*\\.perf\\.js"
      fail_job_on_consistent_failure: false # Performance "failures" might just be warnings; don't block the pipeline.

      notifications:
        slack:
          channel: "#performance-monitoring"
          username: "PerfGuardian"
          icon_emoji: ":chart_with_upwards_trend:"
        github:
          create_issue_on_flaky_detection: false
          comment_on_pr_on_flaky_detection: true # Inform PR author about perf flakiness via comment.
          issue_labels: ["performance", "flaky-perf-test", "P3"]

    - name: "ThirdParty-Integration-Tests"
      description: |
        Tests that rely heavily on external third-party APIs or services. These
        are inherently more prone to flakiness due to factors outside of our control
        (e.g., rate limits, external service downtime, network partitions).
      enabled: true
      max_retries: 6 # Many retries might be needed for highly external dependencies.
      retry_delay_seconds: 20 # Significantly longer delays between retries to allow external services to recover.
      test_command_prefix: "npm run test:external-apis --"
      test_path_pattern: "tests/integrations/third-party/.*\\.test\\.js"
      fail_job_on_consistent_failure: false # Don't block the pipeline for external service flakiness, just monitor and report.

      notifications:
        slack:
          channel: "#third-party-alerts"
          username: "ExternalAPI Monitor"
          icon_emoji: ":cloud:"
        email:
          enabled: true
          recipients: "external-api-team@example.com"
          subject_template: "[3rd Party Flakiness] {{repo}} - {{test_pattern}}"
        github:
          create_issue_on_flaky_detection: true
          issue_labels: ["external-dependency", "flaky-test", "service:third-party"]
          issue_assignees: ["@external-api-owner"]

    - name: "LegacyModuleRegressionTests"
      description: |
        Configuration for older module tests that are inherently less stable due to
        technical debt or complex interdependencies. These often require aggressive
        retries and specific diagnostic steps.
      enabled: true
      max_retries: 8 # Very aggressive retries for highly unstable legacy tests.
      retry_delay_seconds: 25 # Very long delay to give legacy systems more time to recover or warm up.
      test_command_prefix: "docker compose exec legacy-service npm run test:regression --" # Runs tests within a specific Docker container.
      test_path_pattern: "legacy-modules/v1/.*\\.spec\\.js|legacy/tests/.*\\.js"
      fail_job_on_consistent_failure: false # Don't block for legacy system flakiness if it's expected and managed.
      environment_variables: # Specific environment variables for legacy test runs.
        - name: "LEGACY_ENV_MODE"
          value: "FLAKY_CHECK"
          description: "Activates a specific mode in the legacy environment for flaky checks."
        - name: "LEGACY_DB_CONN_POOL_SIZE"
          value: "5"
          description: "Adjusts database connection pool size for legacy tests."
      notifications:
        slack:
          channel: "#legacy-system-alerts"
          username: "LegacyGuard"
        email:
          enabled: true
          recipients: "legacy-team@example.com"
          subject_template: "[Legacy Flakiness] {{repo}} - {{test_pattern}}"
        github:
          create_issue_on_flaky_detection: false # Too many issues might be generated for legacy flakiness.
          comment_on_pr_on_flaky_detection: true # But still inform the PR author directly.
      reporting_and_integration:
        external_reporter:
          enabled: true
          endpoint_url: "https://legacy-dashboard.com/api/flaky-events"
          api_key_secret_name: "LEGACY_REPORTING_API_KEY"
        artifacts:
          save_logs: true
          log_directory: "legacy-test-logs/"
        custom_hooks:
          post_fail_retry_script:
            enabled: true
            path: ".github/scripts/legacy-troubleshoot.sh"
            arguments: ["--service-restart", "--collect-diagnostics", "--test-id={{test_id}}"]
            description: "Attempt service restart and collect diagnostic logs after a legacy test failure."

  # --- Advanced Reporting & Integration ---
  #
  # This section provides configuration options for integrating flaky test detection
  # with external tools, generating detailed artifacts, and pushing metrics to monitoring systems.
  # These integrations help in long-term analysis, visualization, and deeper debugging.
  #
  reporting_and_integration:
    # Configuration for sending flaky test data to an external reporting service
    # or a custom dashboard for long-term trend analysis and visualization.
    external_reporter:
      enabled: false # Set to true to enable external reporting
      # `endpoint_url`: The HTTP(S) endpoint URL of your external reporting service
      #                 (e.g., an internal dashboard, Datadog RUM, custom data lake).
      endpoint_url: "https://your-flaky-test-dashboard.com/api/v1/flaky-report"
      # `api_key_secret_name`: The name of the GitHub secret containing the API Key for authentication.
      api_key_secret_name: "FLAKY_REPORTING_API_KEY"
      # `data_format`: The data format for the payload (e.g., "json", "xml", "form-urlencoded").
      data_format: "json"
      # `custom_headers`: Additional custom HTTP headers to include with the request.
      custom_headers:
        "Content-Type": "application/json"
        "X-App-Source": "GitHub-Actions-Flaky-Detector"
        "Accept": "application/json"
        "Authorization": "Bearer {{api_key}}" # Example if using bearer token from secret.
      # `payload_template`: Defines the structure of the JSON/XML payload. Placeholders are supported.
      payload_template:
        event_type: "flaky_test_run"
        timestamp: "{{current_timestamp}}"
        run_details:
          workflow_run_id: "{{github_run_id}}"
          workflow_url: "{{workflow_url}}"
          repository: "{{repo}}"
          branch: "{{branch}}"
          commit_sha: "{{sha}}"
          actor: "{{github_actor}}"
        test_summary:
          total_tests_analyzed: "{{total_tests_analyzed}}"
          flaky_detected_count: "{{flaky_count}}"
          consistent_failure_count: "{{consistent_failure_count}}"
          test_results: "{{detailed_results_json_string}}" # JSON string of individual test outcomes.

    # Settings for generating and saving detailed test execution artifacts.
    # These artifacts can be uploaded to GitHub Actions artifacts storage for later inspection
    # and debugging purposes, especially for reproducing or understanding flaky failures.
    artifacts:
      # `save_logs`: Enable saving the standard output and error logs from each test execution attempt.
      save_logs: true
      log_directory: "flaky-test-logs/" # Directory where log files are collected from within the workspace.
      log_file_pattern: "*.log" # Glob pattern for log files within the `log_directory` to be uploaded.
      # `save_screenshots_on_failure`: Enable saving screenshots (especially relevant for UI tests)
      #                               taken automatically at the point of test failure.
      save_screenshots_on_failure: true
      screenshot_directory: "flaky-test-screenshots/" # Directory where screenshots are saved.
      screenshot_file_pattern: "*.png" # Glob pattern for screenshot files.
      # `save_videos_on_failure`: Enable saving video recordings of test execution, common in UI testing frameworks.
      save_videos_on_failure: false # Disable by default as videos can be large.
      video_directory: "flaky-test-videos/"
      video_file_pattern: "*.mp4"
      # `save_test_reports`: Enable saving detailed test reports (e.g., Junit XML, JSON reports)
      #                      from each test run. These are useful for parsing by other tools
      #                      or for integrating into test management systems.
      save_test_reports: true
      test_report_directory: "flaky-test-reports/"
      test_report_file_pattern: "*.xml" # Example for JUnit XML reports.

    # Integration with monitoring and metrics dashboards (e.g., Grafana, DataDog, Prometheus).
    # This allows you to track flaky test trends over time, visualize impact, and set up alerts
    # based on the health of your test suite.
    monitoring_metrics:
      enabled: false # Set to true to enable pushing metrics to an external system.
      # `target_platform`: The name of the monitoring platform where metrics will be pushed
      #                    (e.g., "datadog", "prometheus_pushgateway", "custom_script").
      target_platform: "datadog"
      # `metric_prefix`: A common prefix for all metrics generated by the flaky test detector
      #                  to organize them within your monitoring system (e.g., "ci.flaky_tests.").
      metric_prefix: "ci.flaky_tests."
      # `metrics_definitions`: A list of specific metrics to capture and their types (e.g., counter, gauge, histogram).
      metrics_definitions:
        - name: "total_runs"
          type: "counter"
          description: "Total number of flaky test detection workflow runs initiated."
        - name: "flaky_tests_detected_count"
          type: "gauge"
          description: "Number of unique tests identified as flaky (passed on at least one retry)."
        - name: "consistent_failures_count"
          type: "gauge"
          description: "Number of unique tests that consistently failed across all retries."
        - name: "average_retries_for_flaky"
          type: "gauge"
          description: "Average number of retries needed for tests that eventually passed, indicating level of flakiness."
        - name: "test_run_duration_seconds"
          type: "histogram"
          description: "Duration of the overall flaky test detection process in seconds."
        - name: "flaky_test_failure_rate"
          type: "gauge"
          description: "Percentage of initial failures for tests marked as flaky."
      # `global_tags`: A list of key-value pair tags to apply to all pushed metrics.
      #                Useful for filtering/segmenting metrics by environment, service, team, etc.
      global_tags:
        - "env:ci"
        - "team:quality-engineering"
        - "application:main-app"
        - "monitor_source:github-actions"
      # `api_endpoint_secret_name`: GitHub secret for the monitoring platform's API endpoint URL.
      api_endpoint_secret_name: "DATADOG_API_ENDPOINT"
      # `api_key_secret_name`: GitHub secret for the monitoring platform's API key.
      api_key_secret_name: "DATADOG_API_KEY"

    # Define custom hooks or scripts to run at different stages of the flaky detection process.
    # These allow for highly customized actions based on the outcome of test runs,
    # enabling integration with specialized internal tools or custom diagnostics.
    custom_hooks:
      # `pre_run_script`: Script to execute before any test attempts are made for a group.
      pre_run_script:
        enabled: false
        path: ".github/scripts/pre-flaky-run.sh"
        arguments: ["--setup-test-data", "--clean-environment"]
        description: "Executes environment setup or test data seeding before the flaky test suite begins."
      # `post_fail_retry_script`: Script to execute after a test attempt fails, but before a retry.
      post_fail_retry_script:
        enabled: false
        path: ".github/scripts/diagnose-failure.py"
        arguments: ["--collect-logs", "--capture-state", "--test-id={{test_id}}", "--attempt={{attempt_number}}"]
        description: "Runs diagnostic tools or state capture scripts immediately after a test failure to aid debugging."
      # `post_success_script`: Script to execute after a test passes (either initially or on a retry).
      post_success_script:
        enabled: false
        path: ".github/scripts/post-success-action.sh"
        arguments: ["--clear-temp-data", "--log-success"]
        description: "Performs cleanup or success-specific logging actions after a test passes."
      # `post_run_script`: Script to execute after the entire flaky detection process for a group completes.
      post_run_script:
        enabled: true
        path: ".github/scripts/upload-summary-report.sh"
        arguments: ["--report-path={{report_output_path}}", "--upload-target=s3", "--workflow-id={{github_run_id}}"]
        description: "Final script to process reports, upload artifacts to cloud storage, or trigger downstream workflows."

  # --- Configuration Health Checks and Validation ---
  #
  # This section provides configuration to help validate the integrity and correctness
  # of this YAML configuration file itself, and mechanisms to ensure the flaky
  # detection system is operational and correctly set up.
  #
  health_checks:
    # `dry_run_enabled`: If true, the CI workflow will parse this configuration and
    #                    simulate the test execution and notification logic without
    #                    actually running tests or sending external notifications.
    #                    This is extremely useful for testing configuration changes
    #                    without incurring actual CI time or spamming channels.
    dry_run_enabled: false
    # `validation_rules`: A list of rules or checks to perform on this configuration file.
    #                     These rules can be implemented by the runner script to ensure
    #                     that required fields are present, patterns are syntactically valid,
    #                     and referenced secrets exist, improving robustness.
    validation_rules:
      - name: "RequiredFieldsCheck"
        type: "schema_validation"
        description: "Ensures all mandatory fields (e.g., max_retries, test_command_prefix) are present and have valid types."
        severity: "error" # Critical validation failure, should block.
      - name: "RegexPatternSyntax"
        type: "regex_validation"
        description: "Validates that all 'test_path_pattern' fields contain syntactically valid regular expressions."
        severity: "error"
      - name: "SecretExistenceCheck"
        type: "github_secrets_check"
        description: "Verifies that specified GitHub secret names (e.g., for webhooks) actually exist in the repository."
        severity: "warning" # A warning, as missing secrets might just mean a disabled feature.
      - name: "CommandPrefixExecutable"
        type: "shell_command_check"
        description: "Checks if the base commands in 'test_command_prefix' are valid and executable (e.g., 'npm' is in PATH)."
        severity: "warning"
    # `on_validation_failure`: Determines the CI workflow's behavior if any validation rule fails.
    #                          - `fail_workflow`: The workflow will immediately fail, indicating a critical config error.
    #                          - `warn_and_continue`: The workflow will log warnings but continue execution, for less critical issues.
    on_validation_failure: "fail_workflow"
    # `enable_periodic_self_test`: If true, the workflow will periodically run a small,
    #                              dummy test using this configuration to ensure the system is operational
    #                              and can process its own configuration correctly.
    enable_periodic_self_test: false
    self_test_interval_days: 7 # How often to run the self-test (e.g., every 7 days).

# --- General Guidance for Flaky Test Management ---
# 1. Prioritize Fixing: While detection is crucial, the ultimate goal of any flaky test strategy
#    is to identify and fix the root causes of flakiness. Use the reports and notifications
#    generated by this system to create actionable tasks for your development and QA teams.
# 2. Monitor Trends: Regularly review the metrics and reports generated over time. Are certain
#    test groups becoming flakier? Is the average retry count increasing? These trends can
#    signal deeper issues in your application, infrastructure, or testing practices.
# 3. Educate Your Team: Ensure all developers and QA engineers understand what flaky tests are,
#    why they are problematic, and how to effectively use the information provided by this system
#    to contribute to a more stable test suite.
# 4. Iterative Improvement: Start with a simple configuration (e.g., just global settings and Slack alerts).
#    Gradually add complexity (e.g., more `test_groups`, advanced reporting, custom hooks)
#    as you gain experience, identify specific needs, and mature your flaky test management process.
# 5. Environment Consistency: Strive for highly consistent and isolated test environments. Many flaky
#    tests stem from unmanaged shared resources, race conditions, or subtle environmental variations.
#    Robust environments are a cornerstone of reliable testing.
#
# This file serves as a powerful tool to bring transparency and control to the challenging
# problem of flaky tests in modern CI/CD pipelines.