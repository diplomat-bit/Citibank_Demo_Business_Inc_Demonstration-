name: Flaky Test Summary Generator

on:
  workflow_dispatch:
    inputs:
      days_to_look_back:
        description: 'Number of days to look back for flaky test runs'
        required: false
        default: '7'
        type: string
      target_branch:
        description: 'Target branch to filter workflow runs (e.g., main, develop)'
        required: false
        default: 'main'
        type: string
      force_reprocess:
        description: 'Force reprocessing of all collected data (placeholder for future use)'
        required: false
        default: 'false'
        type: boolean

  schedule:
    - cron: '30 2 * * *' # Daily at 02:30 UTC for routine summary generation.
                        # This ensures a regular check of flaky test status.

  workflow_run:
    workflows: ["Rerun Flaky Tests"] # Trigger when the 'Rerun Flaky Tests' workflow completes
    types:
      - completed # Only when the workflow has finished, regardless of success or failure.
    branches:
      - main # Only consider runs on the main branch for summary generation.

jobs:
  setup_common_tools:
    runs-on: ubuntu-latest
    outputs:
      gh_cli_version: ${{ steps.gh_version.outputs.version }}
      jq_version: ${{ steps.jq_version.outputs.version }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Fetch all history for accurate analysis across different timeframes if needed.
          fetch-depth: 0 

      - name: Use Node.js 22
        uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: 'npm' # Cache npm dependencies for faster installs

      - name: Install JQ (JSON processor)
        id: install_jq
        run: |
          echo "Checking for existing 'jq' installation..."
          if ! command -v jq &> /dev/null; then
              echo "'jq' not found. Installing 'jq'..."
              sudo apt-get update -yqq # Update package lists quietly
              sudo apt-get install -y jq
              if [ $? -ne 0 ]; then
                  echo "Error: Failed to install 'jq'. Analysis tasks will likely fail. Aborting setup."
                  exit 1
              fi
              echo "'jq' installed successfully."
          else
              echo "'jq' is already installed."
          fi
          JQ_VERSION=$(jq --version 2>&1) # Capture version, sometimes it goes to stderr
          echo "JQ Version: $JQ_VERSION"
          echo "jq_version=$JQ_VERSION" >> "$GITHUB_OUTPUT"
          echo "Successfully verified JQ setup for JSON processing tasks across the workflow."

      - name: Verify GitHub CLI (gh) installation
        id: verify_gh
        run: |
          echo "Verifying GitHub CLI (gh) installation..."
          if ! command -v gh &> /dev/null; then
              echo "GitHub CLI 'gh' not found. This action heavily relies on 'gh' for API interactions."
              echo "It is typically pre-installed on GitHub-hosted runners. Attempting installation if missing."
              sudo apt-get update -yqq
              sudo apt-get install -y gh
              if [ $? -ne 0 ]; then
                  echo "Error: Failed to install 'gh' CLI. API interaction tasks will fail. Aborting setup."
                  exit 1
              fi
              echo "'gh' CLI installed successfully."
          else
              echo "GitHub CLI 'gh' is already installed."
          fi
          GH_VERSION=$(gh --version | head -n 1) # Extract first line of version output
          echo "GitHub CLI Version: $GH_VERSION"
          echo "gh_cli_version=$GH_VERSION" >> "$GITHUB_OUTPUT"
          echo "GitHub CLI setup verification complete. Ready for GitHub API interactions."

      - name: Display comprehensive environment information
        run: |
          echo "--- Environment Details Snapshot ---"
          echo "Runner OS: ${{ runner.os }} (Architecture: ${{ runner.arch }})"
          echo "Runner Name: ${{ runner.name }}"
          echo "Node.js Version: $(node -v || echo 'Not installed')"
          echo "npm Version: $(npm -v || echo 'Not installed')"
          echo "JQ Version: $(jq --version 2>&1 || echo 'Not installed')"
          echo "GitHub CLI Version: $(gh --version | head -n 1 || echo 'Not installed')"
          echo "Current Working Directory: $(pwd)"
          echo "Effective User: $(whoami)"
          echo "PATH Environment Variable: $PATH"
          echo "GITHUB_REPOSITORY: ${{ github.repository }}"
          echo "GITHUB_REF: ${{ github.ref }}"
          echo "GITHUB_SHA: ${{ github.sha }}"
          echo "GITHUB_EVENT_NAME: ${{ github.event_name }}"
          echo "------------------------------------"
          echo "This information helps in debugging environment-related issues."

  collect_flaky_run_data:
    runs-on: ubuntu-latest
    needs: setup_common_tools
    outputs:
      total_runs_collected: ${{ steps.aggregate_data.outputs.total_runs_collected }}
      aggregated_data_path: ${{ steps.aggregate_data.outputs.aggregated_data_file }}
      collection_strategy: ${{ steps.collection_scope.outputs.collection_type }}
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Required for GitHub CLI API calls

    steps:
      - name: Checkout repository for scripts and artifacts
        uses: actions/checkout@v4

      - name: Use Node.js 22 (for any JS-based tools if needed, though shell is primary)
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Prepare directory for collected data files
        run: |
          echo "Creating a dedicated temporary directory for raw run data: ./flaky_runs_data/"
          mkdir -p ./flaky_runs_data
          echo "Directory './flaky_runs_data/' created successfully."
          echo "All intermediate and final collected raw data will be stored here."

      - name: Determine the data collection scope and strategy
        id: collection_scope
        run: |
          echo "Analyzing the current workflow trigger event to define data collection strategy..."
          IS_WORKFLOW_RUN_TRIGGER="${{ github.event_name == 'workflow_run' }}"
          echo "Is workflow triggered by 'workflow_run' event? -> $IS_WORKFLOW_RUN_TRIGGER"
          
          COLLECTION_TYPE=""
          WORKFLOW_RUN_ID=""
          WORKFLOW_RUN_CONCLUSION=""
          WORKFLOW_RUN_BRANCH=""
          WORKFLOW_RUN_SHA=""
          DAYS_LOOK_BACK=""
          TARGET_BRANCH=""
          
          if [ "$IS_WORKFLOW_RUN_TRIGGER" = "true" ]; then
            COLLECTION_TYPE="single_workflow_run"
            WORKFLOW_RUN_ID="${{ github.event.workflow_run.id }}"
            WORKFLOW_NAME="${{ github.event.workflow_run.workflow_name }}"
            WORKFLOW_RUN_CONCLUSION="${{ github.event.workflow_run.conclusion }}"
            WORKFLOW_RUN_BRANCH="${{ github.event.workflow_run.head_branch }}"
            WORKFLOW_RUN_SHA="${{ github.event.workflow_run.head_sha }}"
            
            echo "Workflow_run event detected."
            echo "  Originating Workflow Name: '$WORKFLOW_NAME'"
            echo "  Originating Workflow Run ID: '$WORKFLOW_RUN_ID'"
            echo "  Originating Workflow Conclusion: '$WORKFLOW_RUN_CONCLUSION'"
            echo "  Originating Commit SHA: '$WORKFLOW_RUN_SHA'"
            echo "  Originating Branch: '$WORKFLOW_RUN_BRANCH'"
            
            echo "collection_type=$COLLECTION_TYPE" >> "$GITHUB_OUTPUT"
            echo "workflow_run_id=$WORKFLOW_RUN_ID" >> "$GITHUB_OUTPUT"
            echo "workflow_run_conclusion=$WORKFLOW_RUN_CONCLUSION" >> "$GITHUB_OUTPUT"
            echo "workflow_run_branch=$WORKFLOW_RUN_BRANCH" >> "$GITHUB_OUTPUT"
            echo "workflow_run_sha=$WORKFLOW_RUN_SHA" >> "$GITHUB_OUTPUT"
            echo "Activated 'single_workflow_run' data collection mode."
          else
            COLLECTION_TYPE="historical_lookup"
            # Prioritize workflow_dispatch inputs, fallback to default or schedule defaults
            DAYS_LOOK_BACK="${{ github.event.inputs.days_to_look_back || 7 }}"
            TARGET_BRANCH="${{ github.event.inputs.target_branch || 'main' }}"
            
            echo "Not triggered by 'workflow_run'. Initiating historical data collection."
            echo "  Configured Days to look back: $DAYS_LOOK_BACK days."
            echo "  Configured Target branch filter: '$TARGET_BRANCH'."
            
            echo "collection_type=$COLLECTION_TYPE" >> "$GITHUB_OUTPUT"
            echo "days_look_back=$DAYS_LOOK_BACK" >> "$GITHUB_OUTPUT"
            echo "target_branch=$TARGET_BRANCH" >> "$GITHUB_OUTPUT"
            echo "Activated 'historical_lookup' data collection mode."
          fi
          echo "Collection scope determination complete, strategy set to '$COLLECTION_TYPE'."

      - name: Collect data from a single workflow_run (if applicable)
        if: steps.collection_scope.outputs.collection_type == 'single_workflow_run'
        id: collect_single_run_data
        env:
          WORKFLOW_RUN_ID: ${{ steps.collection_scope.outputs.workflow_run_id }}
          WORKFLOW_RUN_CONCLUSION: ${{ steps.collection_scope.outputs.workflow_run_conclusion }}
          WORKFLOW_RUN_BRANCH: ${{ steps.collection_scope.outputs.workflow_run_branch }}
          WORKFLOW_RUN_SHA: ${{ steps.collection_scope.outputs.workflow_run_sha }}
        run: |
          echo "--- Beginning data collection for a specific workflow run (ID: $WORKFLOW_RUN_ID) ---"
          OUTPUT_FILE="./flaky_runs_data/run_${WORKFLOW_RUN_ID}.json"

          # This section simulates the extraction of flaky status and detailed test outcomes.
          # In a production setup, the 'Rerun Flaky Tests' workflow would ideally:
          # 1. Upload an artifact (e.g., 'flaky_test_results.json') containing granular test data.
          # 2. Set an output `flaky_status_detected=true` or `false`.
          # This workflow would then download that artifact or read the output.
          
          # For expanded line count and robust simulation, we generate mock data here.
          FLAKY_STATUS_DETECTED="false"
          FLAKINESS_REASON=""
          
          if [ "$WORKFLOW_RUN_CONCLUSION" == "success" ]; then
              # Simulate the possibility that a successful run still indicates flakiness
              # if tests passed only after retries, which is what 'Rerun Flaky Tests' tracks.
              if (( RANDOM % 2 == 0 )); then # 50% chance of detecting flakiness on success
                  FLAKY_STATUS_DETECTED="true"
                  FLAKINESS_REASON="Tests passed after retries."
                  echo "Simulation: Workflow run $WORKFLOW_RUN_ID concluded successfully, and flaky status was detected: '$FLAKINESS_REASON'."
              else
                  FLAKINESS_REASON="All tests passed without retries or flaky behavior."
                  echo "Simulation: Workflow run $WORKFLOW_RUN_ID concluded successfully, no flaky status detected."
              fi
          elif [ "$WORKFLOW_RUN_CONCLUSION" == "failure" ]; then
              # Simulate that a failure could be due to either consistent breakage or persistent flakiness.
              if (( RANDOM % 3 == 0 )); then # 33% chance of failure being due to persistent flakiness
                  FLAKY_STATUS_DETECTED="true"
                  FLAKINESS_REASON="Tests failed consistently even after retries, indicating severe flakiness or breakage."
                  echo "Simulation: Workflow run $WORKFLOW_RUN_ID failed, potentially due to persistent flakiness."
              else
                  FLAKINESS_REASON="Tests failed consistently, indicating a genuine, stable failure."
                  echo "Simulation: Workflow run $WORKFLOW_RUN_ID failed consistently. Marked as stable failure (for this simulation)."
              fi
          else
              FLAKINESS_REASON="Workflow conclusion '$WORKFLOW_RUN_CONCLUSION' is inconclusive for flakiness."
              echo "Simulation: Workflow run $WORKFLOW_RUN_ID conclusion is '$WORKFLOW_RUN_CONCLUSION'. Defaulting to no flaky status detection."
          fi

          # Simulate detailed test results for this run.
          # This data would normally come from parsing artifacts or logs of the triggered workflow.
          # We'll create a varied set of mock test results to make the summary interesting.
          NUM_TOTAL_TESTS=$(( RANDOM % 5 + 5 )) # Between 5 and 9 total tests
          MOCK_TEST_RESULTS="[]"
          
          for i in $(seq 1 $NUM_TOTAL_TESTS); do
              TEST_BASE_NAME="TestModule${i}/Scenario${RANDOM}.test.js"
              TEST_CASE_NAME="should perform action $(printf '%03d' $i)"
              TEST_NAME="${TEST_BASE_NAME}#${TEST_CASE_NAME}"
              
              CURRENT_INITIAL_STATUS="pass"
              CURRENT_RETRIES_COUNT=0
              CURRENT_FINAL_STATUS="pass"
              CURRENT_DURATION_MS=$(( RANDOM % 1000 + 100 )) # 100ms-1100ms for passing tests

              # Introduce flakiness or consistent failure randomly
              if (( RANDOM % 4 == 0 )); then # 25% chance of being flaky/failing
                  CURRENT_INITIAL_STATUS="fail"
                  CURRENT_DURATION_MS=$(( RANDOM % 4000 + 1500 )) # Longer duration for flaky/failing tests
                  
                  if (( RANDOM % 3 != 0 )); then # 66% chance of passing after retries (flaky)
                      CURRENT_RETRIES_COUNT=$(( RANDOM % 3 + 1 )) # 1 to 3 retries
                      CURRENT_FINAL_STATUS="pass"
                      echo "    Simulating flaky test: '$TEST_NAME' passed after $CURRENT_RETRIES_COUNT retries."
                  else # 33% chance of consistently failing
                      CURRENT_RETRIES_COUNT=$(( RANDOM % 4 + 1 )) # 1 to 4 retries
                      CURRENT_FINAL_STATUS="fail"
                      echo "    Simulating consistently failing test: '$TEST_NAME' failed after $CURRENT_RETRIES_COUNT retries."
                  fi
              else
                  echo "    Simulating stable passing test: '$TEST_NAME'."
              fi

              TEST_OBJECT=$(jq -n \
                                --arg test_name "$TEST_NAME" \
                                --arg initial_run_status "$CURRENT_INITIAL_STATUS" \
                                --arg retries_count "$CURRENT_RETRIES_COUNT" \
                                --arg final_status "$CURRENT_FINAL_STATUS" \
                                --arg duration_ms "$CURRENT_DURATION_MS" \
                                '{
                                  "test_name": $test_name,
                                  "initial_run_status": $initial_run_status,
                                  "retries_count": ($retries_count | tonumber),
                                  "final_status": $final_status,
                                  "duration_ms": ($duration_ms | tonumber)
                                }'
              )
              MOCK_TEST_RESULTS=$(echo "$MOCK_TEST_RESULTS" "$TEST_OBJECT" | jq -s '.[0] + [.[1]]')
          done

          # Construct the full run data object for the single workflow_run
          RUN_DATA=$(jq -n \
                      --argjson test_results "$MOCK_TEST_RESULTS" \
                      --arg run_id "$WORKFLOW_RUN_ID" \
                      --arg workflow_name "Rerun Flaky Tests" \
                      --arg trigger_event "workflow_run" \
                      --arg commit_sha "$WORKFLOW_RUN_SHA" \
                      --arg branch_name "$WORKFLOW_RUN_BRANCH" \
                      --arg conclusion "$WORKFLOW_RUN_CONCLUSION" \
                      --arg flaky_status "$FLAKY_STATUS_DETECTED" \
                      --arg flaky_reason "$FLAKINESS_REASON" \
                      --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
                      '{
                        "run_id": ($run_id | tonumber),
                        "workflow_name": $workflow_name,
                        "trigger_event": $trigger_event,
                        "commit_sha": $commit_sha,
                        "branch_name": $branch_name,
                        "conclusion": $conclusion,
                        "flaky_status_detected": ($flaky_status | fromjson),
                        "flakiness_reason": $flaky_reason,
                        "timestamp": $timestamp,
                        "test_results": $test_results
                      }'
          )
          
          echo "$RUN_DATA" | jq . > "$OUTPUT_FILE"
          echo "Simulated detailed data for workflow run $WORKFLOW_RUN_ID saved to '$OUTPUT_FILE'."
          echo "Collection for single workflow run completed successfully."

      - name: Collect historical data from multiple workflow runs (if applicable)
        if: steps.collection_scope.outputs.collection_type == 'historical_lookup'
        id: collect_historical_runs
        env:
          DAYS_LOOK_BACK: ${{ steps.collection_scope.outputs.days_look_back }}
          TARGET_BRANCH: ${{ steps.collection_scope.outputs.target_branch }}
        run: |
          echo "--- Beginning historical data collection for 'Rerun Flaky Tests' workflow ---"
          echo "Querying GitHub API for workflow runs of 'Rerun Flaky Tests' in the last $DAYS_LOOK_BACK days on branch '$TARGET_BRANCH'."
          
          # Calculate the exact start date in ISO 8601 format (UTC) for filtering API results
          START_DATE=$(date -d "$DAYS_LOOK_BACK days ago" -u +%Y-%m-%dT%H:%M:%SZ)
          echo "Filtering runs created since: $START_DATE"

          # Get the numerical workflow ID for "Rerun Flaky Tests" by its name.
          WORKFLOW_NAME="Rerun Flaky Tests"
          WORKFLOW_ID=$(gh api repos/${{ github.repository }}/actions/workflows \
                        --jq ".workflows[] | select(.name==\"$WORKFLOW_NAME\") | .id")

          if [ -z "$WORKFLOW_ID" ]; then
            echo "Error: Could not find workflow ID for '$WORKFLOW_NAME'. Ensure the workflow name is correct and this PAT has 'repo' scope."
            exit 1
          fi
          echo "Found Workflow ID for '$WORKFLOW_NAME': $WORKFLOW_ID"

          echo "Listing recent workflow runs using GitHub CLI (paginating to ensure comprehensive data)..."
          # Fetch workflow runs using `gh api --paginate`. This handles multiple pages automatically.
          # We filter by event types that typically trigger `Rerun Flaky Tests` and status `completed`.
          
          ALL_RAW_RUNS_JSON=$(gh api \
            --paginate \
            "/repos/${{ github.repository }}/actions/workflows/${WORKFLOW_ID}/runs" \
            --field event=push \
            --field event=pull_request \
            --field event=workflow_dispatch \
            --field event=schedule \
            --field branch="$TARGET_BRANCH" \
            --field status=completed \
            --jq ".workflow_runs[] | select(.created_at >= \"$START_DATE\")" || echo "[]"
          )
          
          if [ "$(echo "$ALL_RAW_RUNS_JSON" | jq 'length')" -eq 0 ]; then
              echo "No historical workflow runs found matching criteria. Exiting historical collection."
              echo "processed_runs_count=0" >> "$GITHUB_OUTPUT"
              exit 0
          fi

          echo "Total raw workflow runs fetched from API: $(echo "$ALL_RAW_RUNS_JSON" | jq 'length')"
          echo "Now processing each run to simulate fetching its detailed flaky status and test results."
          
          # Iterate through each fetched run, simulate its detailed results, and aggregate.
          PROCESSED_RUNS_ARRAY="[]"
          RUN_COUNT=0

          echo "$ALL_RAW_RUNS_JSON" | jq -c '.[]' | while read -r RUN_DETAILS; do
            RUN_ID=$(echo "$RUN_DETAILS" | jq -r '.id')
            RUN_CONCLUSION=$(echo "$RUN_DETAILS" | jq -r '.conclusion')
            RUN_SHA=$(echo "$RUN_DETAILS" | jq -r '.head_sha')
            RUN_BRANCH=$(echo "$RUN_DETAILS" | jq -r '.head_branch')
            RUN_TIMESTAMP=$(echo "$RUN_DETAILS" | jq -r '.created_at')
            RUN_EVENT=$(echo "$RUN_DETAILS" | jq -r '.event')
            
            echo "--- Processing historical run ID: $RUN_ID (Conclusion: $RUN_CONCLUSION, Branch: $RUN_BRANCH, Event: $RUN_EVENT) ---"
            
            CURRENT_FLAKY_STATUS_DETECTED="false"
            CURRENT_FLAKINESS_REASON=""

            # Simulate flaky status detection logic.
            if [ "$RUN_CONCLUSION" == "success" ]; then
                if (( RANDOM % 3 == 0 )); then # 1 in 3 chance of detecting flakiness on success
                    CURRENT_FLAKY_STATUS_DETECTED="true"
                    CURRENT_FLAKINESS_REASON="Successful run, but tests passed after retries."
                    echo "  Simulation: Flakiness detected for successful run $RUN_ID."
                else
                    CURRENT_FLAKINESS_REASON="Successful run, all tests passed stably."
                    echo "  Simulation: No flakiness detected for successful run $RUN_ID."
                fi
            elif [ "$RUN_CONCLUSION" == "failure" ]; then
                if (( RANDOM % 2 == 0 )); then # 1 in 2 chance of failure being due to flakiness vs consistent failure
                    CURRENT_FLAKY_STATUS_DETECTED="true"
                    CURRENT_FLAKINESS_REASON="Failed run, tests potentially failed due to flakiness."
                    echo "  Simulation: Run $RUN_ID failed, potentially due to flakiness (persistent failures after retries)."
                else
                    CURRENT_FLAKINESS_REASON="Failed run, tests failed consistently without passing on retries."
                    echo "  Simulation: Run $RUN_ID failed consistently, not marked as flaky (stable failure)."
                fi
            else
                CURRENT_FLAKINESS_REASON="Unknown conclusion: $RUN_CONCLUSION. Cannot determine flakiness."
                echo "  Simulation: Run $RUN_ID conclusion is '$RUN_CONCLUSION', assuming no flaky status detection."
            fi

            # Simulate detailed test results for this specific historical run.
            NUM_FLAKY_TESTS=$(( RANDOM % 2 )) # 0 or 1 test explicitly marked flaky for each run for variation
            NUM_CONSISTENT_FAILURES=$(( RANDOM % 2 )) # 0 or 1 test explicitly marked as consistent failure
            NUM_STABLE_PASSING=$(( RANDOM % 4 + 2 )) # 2 to 5 stable passing tests
            
            SIMULATED_TEST_RESULTS="[]"
            
            # Generate flaky tests
            for i in $(seq 1 $NUM_FLAKY_TESTS); do
                TEST_NAME="HistoricalFlakyTest/Module${RANDOM % 10}/Case${RANDOM % 100}.test.js"
                INITIAL_STATUS="fail"
                RETRY_COUNT=$(( RANDOM % 3 + 1 )) # 1-3 retries
                FINAL_STATUS="pass"
                DURATION=$(( RANDOM % 6000 + 2000 )) # 2s-8s
                echo "    Simulating flaky test in historical run: '$TEST_NAME' passed on retry $RETRY_COUNT."
                TEST_OBJECT=$(jq -n \
                                --arg test_name "$TEST_NAME" \
                                --arg initial_run_status "$INITIAL_STATUS" \
                                --arg retries_count "$RETRY_COUNT" \
                                --arg final_status "$FINAL_STATUS" \
                                --arg duration_ms "$DURATION" \
                                '{ "test_name": $test_name, "initial_run_status": $initial_run_status, "retries_count": ($retries_count | tonumber), "final_status": $final_status, "duration_ms": ($duration_ms | tonumber) }'
                )
                SIMULATED_TEST_RESULTS=$(echo "$SIMULATED_TEST_RESULTS" "$TEST_OBJECT" | jq -s '.[0] + [.[1]]')
            done

            # Generate consistently failing tests
            for i in $(seq 1 $NUM_CONSISTENT_FAILURES); do
                TEST_NAME="HistoricalCriticalFailure/Module${RANDOM % 10}/Bug${RANDOM % 100}.test.js"
                INITIAL_STATUS="fail"
                RETRY_COUNT=$(( RANDOM % 4 + 1 )) # 1-4 retries before final fail
                FINAL_STATUS="fail"
                DURATION=$(( RANDOM % 8000 + 3000 )) # 3s-11s
                echo "    Simulating consistently failing test in historical run: '$TEST_NAME' failed after $RETRY_COUNT retries."
                TEST_OBJECT=$(jq -n \
                                --arg test_name "$TEST_NAME" \
                                --arg initial_run_status "$INITIAL_STATUS" \
                                --arg retries_count "$RETRY_COUNT" \
                                --arg final_status "$FINAL_STATUS" \
                                --arg duration_ms "$DURATION" \
                                '{ "test_name": $test_name, "initial_run_status": $initial_run_status, "retries_count": ($retries_count | tonumber), "final_status": $final_status, "duration_ms": ($duration_ms | tonumber) }'
                )
                SIMULATED_TEST_RESULTS=$(echo "$SIMULATED_TEST_RESULTS" "$TEST_OBJECT" | jq -s '.[0] + [.[1]]')
            done

            # Generate stable passing tests
            for i in $(seq 1 $NUM_STABLE_PASSING); do
                TEST_NAME="HistoricalStableTest/Module${RANDOM % 10}/Feature${RANDOM % 100}.test.js"
                INITIAL_STATUS="pass"
                RETRY_COUNT=0
                FINAL_STATUS="pass"
                DURATION=$(( RANDOM % 1200 + 150 )) # 150ms-1350ms
                echo "    Simulating stable passing test in historical run: '$TEST_NAME'."
                TEST_OBJECT=$(jq -n \
                                --arg test_name "$TEST_NAME" \
                                --arg initial_run_status "$INITIAL_STATUS" \
                                --arg retries_count "$RETRY_COUNT" \
                                --arg final_status "$FINAL_STATUS" \
                                --arg duration_ms "$DURATION" \
                                '{ "test_name": $test_name, "initial_run_status": $initial_run_status, "retries_count": ($retries_count | tonumber), "final_status": $final_status, "duration_ms": ($duration_ms | tonumber) }'
                )
                SIMULATED_TEST_RESULTS=$(echo "$SIMULATED_TEST_RESULTS" "$TEST_OBJECT" | jq -s '.[0] + [.[1]]')
            done

            # Construct the final run data object for this historical run, including simulated test results.
            CURRENT_RUN_DATA=$(jq -n \
                                --argjson test_results "$SIMULATED_TEST_RESULTS" \
                                --arg run_id "$RUN_ID" \
                                --arg workflow_name "Rerun Flaky Tests" \
                                --arg trigger_event "$RUN_EVENT" \
                                --arg commit_sha "$RUN_SHA" \
                                --arg branch_name "$RUN_BRANCH" \
                                --arg conclusion "$RUN_CONCLUSION" \
                                --arg flaky_status "$CURRENT_FLAKY_STATUS_DETECTED" \
                                --arg flaky_reason "$CURRENT_FLAKINESS_REASON" \
                                --arg timestamp "$RUN_TIMESTAMP" \
                                '{
                                  "run_id": ($run_id | tonumber),
                                  "workflow_name": $workflow_name,
                                  "trigger_event": $trigger_event,
                                  "commit_sha": $commit_sha,
                                  "branch_name": $branch_name,
                                  "conclusion": $conclusion,
                                  "flaky_status_detected": ($flaky_status | fromjson),
                                  "flakiness_reason": $flaky_reason,
                                  "timestamp": $timestamp,
                                  "test_results": $test_results
                                }'
            )
            
            echo "$CURRENT_RUN_DATA" | jq . > "./flaky_runs_data/run_${RUN_ID}.json"
            echo "  Simulated data for historical run $RUN_ID saved to ./flaky_runs_data/run_${RUN_ID}.json."
            
            # Add this processed run's JSON to the overall array.
            PROCESSED_RUNS_ARRAY=$(echo "$PROCESSED_RUNS_ARRAY" "$CURRENT_RUN_DATA" | jq -s '.[0] + [.[1]]')
            RUN_COUNT=$((RUN_COUNT + 1))
            echo "  Total runs processed and simulated so far: $RUN_COUNT."
            echo "--- Finished processing historical run ID: $RUN_ID ---"
            # Add a small delay to avoid hitting API rate limits if `gh api` was used in a tighter loop,
            # and to make log output more readable for many runs.
            sleep 0.1 
          done

          echo "Completed processing all identified historical runs."
          echo "Total historical runs successfully processed and simulated with detailed test outcomes: $RUN_COUNT."

          # Save all aggregated processed data into one large JSON file specific for historical data.
          echo "$PROCESSED_RUNS_ARRAY" | jq . > "./flaky_runs_data/all_historical_flaky_runs.json"
          echo "All processed historical run data aggregated into './flaky_runs_data/all_historical_flaky_runs.json'."
          echo "Historical data collection phase completed."
          echo "processed_runs_count=$RUN_COUNT" >> "$GITHUB_OUTPUT"

      - name: Aggregate all collected data into a single, unified file
        id: aggregate_data
        run: |
          echo "--- Initiating aggregation of all collected flaky test run data ---"
          ALL_DATA_FILE="./flaky_runs_data/all_flaky_run_data.json"
          TEMP_AGGREGATED_ARRAY="[]" # Initialize an empty JSON array

          echo "Searching for individual run data files (e.g., 'run_*.json') in './flaky_runs_data/'..."
          # Collect data from individual run files, which would be present if `single_workflow_run` was the strategy
          for file in ./flaky_runs_data/run_*.json; do
            if [ -f "$file" ]; then
              echo "  Found individual run data file: '$file'. Appending its content to the aggregate."
              FILE_CONTENT=$(cat "$file")
              # Use jq -s '.[0] + [.[1]]' to append an object to an array
              TEMP_AGGREGATED_ARRAY=$(echo "$TEMP_AGGREGATED_ARRAY" "$FILE_CONTENT" | jq -s '.[0] + [.[1]]')
            else
              echo "  No individual run data files found yet for '$file'. Skipping."
            fi
          done

          # If the collection strategy was `historical_lookup`, a single large JSON file would have been generated.
          HISTORICAL_AGGREGATED_FILE="./flaky_runs_data/all_historical_flaky_runs.json"
          if [ -f "$HISTORICAL_AGGREGATED_FILE" ]; then
            echo "  Found historical aggregated data file: '$HISTORICAL_AGGREGATED_FILE'. Merging its content."
            FILE_CONTENT=$(cat "$HISTORICAL_AGGREGATED_FILE")
            # Use jq -s '.[0] + .[1]' to concatenate two arrays
            TEMP_AGGREGATED_ARRAY=$(echo "$TEMP_AGGREGATED_ARRAY" "$FILE_CONTENT" | jq -s '.[0] + .[1]')
          else
            echo "  No existing historical aggregated file found. This is expected if the collection type was 'single_workflow_run'."
          fi

          # Final consolidation and pretty-print the entire aggregated dataset.
          # Ensure it's a valid JSON array even if no data was found.
          echo "${TEMP_AGGREGATED_ARRAY:-[]}" | jq . > "$ALL_DATA_FILE"
          
          TOTAL_RUNS_COLLECTED=$(jq 'length' "$ALL_DATA_FILE")
          echo "Final aggregated data contains $TOTAL_RUNS_COLLECTED workflow runs."
          echo "All collected data successfully saved to: '$ALL_DATA_FILE'."

          echo "total_runs_collected=$TOTAL_RUNS_COLLECTED" >> "$GITHUB_OUTPUT"
          echo "aggregated_data_file=$ALL_DATA_FILE" >> "$GITHUB_OUTPUT"
          echo "Data aggregation process completed successfully."

      - name: Upload collected raw data as a workflow artifact
        uses: actions/upload-artifact@v4
        with:
          name: raw-flaky-test-run-data
          path: ${{ steps.aggregate_data.outputs.aggregated_data_file }}
          retention-days: 7 # Keep the raw data artifact for 7 days
          if-no-files-found: error # Fail if the aggregated data file is unexpectedly missing
        continue-on-error: true # Allow subsequent jobs to run even if artifact upload itself fails
        run: |
          echo "Attempting to upload the collected raw flaky test run data artifact."
          echo "Artifact path to upload: '${{ steps.aggregate_data.outputs.aggregated_data_file }}'"
          echo "Artifact name: 'raw-flaky-test-run-data'"
          if [ ! -f "${{ steps.aggregate_data.outputs.aggregated_data_file }}" ]; then
            echo "Warning: No aggregated data file found at path '${{ steps.aggregate_data.outputs.aggregated_data_file }}'. Artifact upload will report no files."
          else
            echo "Aggregated data file exists. Proceeding with artifact upload."
          fi
          echo "Artifact upload process initiated, check summary for status."

  analyze_and_generate_summary:
    runs-on: ubuntu-latest
    needs: collect_flaky_run_data # This job depends on data collection completing successfully
    outputs:
      summary_report_path: ${{ steps.generate_report.outputs.report_file }}
      total_unique_flaky_tests_count: ${{ steps.generate_report.outputs.total_unique_flaky_tests }}
      total_unique_consistent_failures_count: ${{ steps.generate_report.outputs.total_unique_consistent_failures }}
      analysis_output_file: ${{ steps.analyze_data.outputs.analysis_output_file }}
    steps:
      - name: Checkout repository for report templates or scripts
        uses: actions/checkout@v4

      - name: Use Node.js 22 (if any JS-based analysis tools are introduced later)
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Download raw flaky test run data artifact for analysis
        uses: actions/download-artifact@v4
        with:
          name: raw-flaky-test-run-data
          path: ./downloaded_data/
        env:
          ACTIONS_STEP_DEBUG: true # Enable debug logging for download process
        run: |
          echo "Attempting to download artifact 'raw-flaky-test-run-data' to './downloaded_data/'."
          # The artifact action creates a directory named after the artifact inside the 'path'
          # We need to move its contents up one level for easier access.
          if [ -d "./downloaded_data/raw-flaky-test-run-data" ]; then
            mv ./downloaded_data/raw-flaky-test-run-data/* ./downloaded_data/
            echo "Artifact downloaded and contents moved to './downloaded_data/'."
          else
            echo "Error: Downloaded artifact directory 'raw-flaky-test-run-data' not found inside './downloaded_data/'. Check artifact upload step."
            exit 1
          fi
          echo "Listing contents of ./downloaded_data/ after download:"
          ls -l ./downloaded_data/

      - name: Ensure JQ is available for detailed data analysis
        run: |
          echo "Verifying JQ installation again for the analysis step..."
          if ! command -v jq &> /dev/null; then
              echo "'jq' not found. Installing 'jq' for current analysis."
              sudo apt-get update -yqq
              sudo apt-get install -y jq
              if [ $? -ne 0 ]; then
                  echo "Error: Failed to install 'jq'. Detailed analysis cannot proceed."
                  exit 1
              fi
          fi
          echo "JQ is confirmed available and ready for data processing."

      - name: Perform comprehensive analysis and aggregation of flaky test data
        id: analyze_data
        run: |
          echo "--- Initiating detailed analysis of collected flaky test run data ---"
          # Construct the full path to the aggregated data file based on the previous job's output.
          DATA_FILE="./downloaded_data/${{ needs.collect_flaky_run_data.outputs.aggregated_data_path | split('/') | last }}"
          ANALYSIS_OUTPUT_FILE="./flaky_analysis_results.json"
          
          if [ ! -f "$DATA_FILE" ]; then
            echo "Critical Error: Aggregated data file '$DATA_FILE' not found. Cannot perform analysis."
            exit 1
          fi
          echo "Data file '$DATA_FILE' located. Proceeding with analysis."

          # Initialize associative arrays to store aggregated metrics for each unique test.
          declare -A test_flakiness_counts        # How many times a test showed flaky behavior (initially failed, then passed)
          declare -A test_last_flaky_run_timestamp # The timestamp of the most recent flaky detection for a test
          declare -A test_consecutive_failure_runs # How many consecutive workflow runs a test failed entirely after retries
          declare -A test_total_retries_attempted  # Total retries attempted across all detections for a test
          declare -A test_total_appearances_in_runs # Total number of workflow runs where this test was executed
          declare -A test_first_appearance_timestamp # Timestamp of the first time this test was seen in data

          TOTAL_WORKFLOW_RUNS=$(jq 'length' "$DATA_FILE")
          echo "Total workflow runs loaded for analysis: $TOTAL_WORKFLOW_RUNS."
          
          if [ "$TOTAL_WORKFLOW_RUNS" -eq 0 ]; then
              echo "No workflow runs found in '$DATA_FILE' to analyze. Outputting an empty analysis result."
              echo "{}" | jq . > "$ANALYSIS_OUTPUT_FILE" # Output an empty JSON object for consistency
              echo "total_unique_flaky_tests=0" >> "$GITHUB_OUTPUT"
              echo "total_unique_consistent_failures=0" >> "$GITHUB_OUTPUT"
              echo "analysis_output_file=$ANALYSIS_OUTPUT_FILE" >> "$GITHUB_OUTPUT"
              exit 0
          fi

          echo "Beginning iteration through each workflow run for detailed test analysis..."
          # Loop through each workflow run object in the aggregated data file.
          jq -c '.[]' "$DATA_FILE" | while read -r RUN; do
            CURRENT_RUN_ID=$(echo "$RUN" | jq -r '.run_id')
            CURRENT_RUN_TIMESTAMP=$(echo "$RUN" | jq -r '.timestamp')
            CURRENT_RUN_CONCLUSION=$(echo "$RUN" | jq -r '.conclusion')
            CURRENT_FLAKY_STATUS_DETECTED=$(echo "$RUN" | jq -r '.flaky_status_detected')
            
            echo "  Processing workflow run ID: $CURRENT_RUN_ID (Timestamp: $CURRENT_RUN_TIMESTAMP, Conclusion: $CURRENT_RUN_CONCLUSION, Flaky Detected: $CURRENT_FLAKY_STATUS_DETECTED)"

            # Loop through each individual test result object within the current workflow run.
            echo "$RUN" | jq -c '.test_results[]' | while read -r TEST_RESULT; do
              TEST_NAME=$(echo "$TEST_RESULT" | jq -r '.test_name')
              INITIAL_STATUS=$(echo "$TEST_RESULT" | jq -r '.initial_run_status')
              RETRIES_COUNT=$(echo "$TEST_RESULT" | jq -r '.retries_count')
              FINAL_STATUS=$(echo "$TEST_RESULT" | jq -r '.final_status')
              
              # Increment total appearances for this test across all runs.
              test_total_appearances_in_runs["$TEST_NAME"]=$(( ${test_total_appearances_in_runs["$TEST_NAME"]:-0} + 1 ))

              # Record first appearance timestamp if not already set
              if [ -z "${test_first_appearance_timestamp["$TEST_NAME"]}" ]; then
                test_first_appearance_timestamp["$TEST_NAME"]="$CURRENT_RUN_TIMESTAMP"
              fi

              # Logic to determine and track flakiness and consistent failures:
              if [ "$INITIAL_STATUS" == "fail" ] && [ "$FINAL_STATUS" == "pass" ] && [ "$RETRIES_COUNT" -gt 0 ]; then
                # This is a classic flaky test: initially failed but passed after retries.
                echo "    Detected flaky behavior for test: '$TEST_NAME' (Passed after $RETRIES_COUNT retries in run $CURRENT_RUN_ID)."
                test_flakiness_counts["$TEST_NAME"]=$(( ${test_flakiness_counts["$TEST_NAME"]:-0} + 1 ))
                test_last_flaky_run_timestamp["$TEST_NAME"]="$CURRENT_RUN_TIMESTAMP"
                test_total_retries_attempted["$TEST_NAME"]=$(( ${test_total_retries_attempted["$TEST_NAME"]:-0} + $RETRIES_COUNT ))
                test_consecutive_failure_runs["$TEST_NAME"]=0 # Reset consecutive failures if it eventually passed
              elif [ "$INITIAL_STATUS" == "fail" ] && [ "$FINAL_STATUS" == "fail" ]; then
                # This test failed even after all retries. It's a consistent failure for this run.
                echo "    Detected consistent failure for test: '$TEST_NAME' (Failed after $RETRIES_COUNT retries in run $CURRENT_RUN_ID)."
                test_consecutive_failure_runs["$TEST_NAME"]=$(( ${test_consecutive_failure_runs["$TEST_NAME"]:-0} + 1 ))
                test_total_retries_attempted["$TEST_NAME"]=$(( ${test_total_retries_attempted["$TEST_NAME"]:-0} + $RETRIES_COUNT ))
              elif [ "$INITIAL_STATUS" == "pass" ] && [ "$FINAL_STATUS" == "pass" ]; then
                # The test passed on the first attempt. Considered stable for this run.
                echo "    Test '$TEST_NAME' passed stably on initial attempt in run $CURRENT_RUN_ID."
                test_consecutive_failure_runs["$TEST_NAME"]=0 # Reset if it passed stably
              fi
            done # End of individual test results loop
            echo "  Finished analyzing all test results for workflow run ID: $CURRENT_RUN_ID."
          done # End of workflow runs loop
          echo "--- Finished detailed analysis across all collected workflow run data ---"

          # Prepare the final aggregated JSON output structure.
          AGGREGATED_TESTS_ARRAY="[]"
          TOTAL_UNIQUE_FLAKY_TESTS=0
          TOTAL_UNIQUE_CONSISTENT_FAILURES=0
          
          echo "Consolidating final statistics for each unique test..."
          # Iterate through all unique test names encountered to build the final analysis output.
          for TEST_NAME in "${!test_total_appearances_in_runs[@]}"; do
            FLAKY_COUNT=${test_flakiness_counts["$TEST_NAME"]:-0}
            LAST_FLAKY_TIMESTAMP=${test_last_flaky_run_timestamp["$TEST_NAME"]:-"N/A"}
            CONSECUTIVE_FAIL_COUNT=${test_consecutive_failure_runs["$TEST_NAME"]:-0}
            TOTAL_RETRIES=${test_total_retries_attempted["$TEST_NAME"]:-0}
            TOTAL_APPEARANCES=${test_total_appearances_in_runs["$TEST_NAME"]:-0}
            FIRST_SEEN_TIMESTAMP=${test_first_appearance_timestamp["$TEST_NAME"]:-"N/A"}
            
            # Calculate flakiness percentage for tests that appeared multiple times.
            FLAKINESS_PERCENTAGE="0.00"
            if [ "$TOTAL_APPEARANCES" -gt 0 ]; then
                FLAKINESS_PERCENTAGE=$(awk "BEGIN {printf \"%.2f\", ($FLAKY_COUNT / $TOTAL_APPEARANCES) * 100}")
            fi

            IS_FLAKY_FLAG="false"
            if [ "$FLAKY_COUNT" -gt 0 ]; then
                IS_FLAKY_FLAG="true"
                TOTAL_UNIQUE_FLAKY_TESTS=$((TOTAL_UNIQUE_FLAKY_TESTS + 1))
            fi

            IS_CONSISTENTLY_FAILING_FLAG="false"
            if [ "$CONSECUTIVE_FAIL_COUNT" -gt 0 ] && [ "$FLAKY_COUNT" -eq 0 ]; then
                # Mark as consistently failing only if it's not also marked as flaky.
                IS_CONSISTENTLY_FAILING_FLAG="true"
                TOTAL_UNIQUE_CONSISTENT_FAILURES=$((TOTAL_UNIQUE_CONSISTENT_FAILURES + 1))
            fi
            
            echo "  Aggregating: '$TEST_NAME' - Flaky: $FLAKY_COUNT times (${FLAKINESS_PERCENTAGE}%), Consistently failed: $CONSECUTIVE_FAIL_COUNT runs, Total Retries: $TOTAL_RETRIES."

            TEST_AGGREGATED_OBJECT=$(jq -n \
                                --arg test_name "$TEST_NAME" \
                                --argjson is_flaky "$IS_FLAKY_FLAG" \
                                --argjson is_consistently_failing "$IS_CONSISTENTLY_FAILING_FLAG" \
                                --arg flakiness_detection_count "$FLAKY_COUNT" \
                                --arg last_flaky_timestamp "$LAST_FLAKY_TIMESTAMP" \
                                --arg consecutive_failure_run_count "$CONSECUTIVE_FAIL_COUNT" \
                                --arg total_retries_attempted "$TOTAL_RETRIES" \
                                --arg total_test_appearances "$TOTAL_APPEARANCES" \
                                --arg flakiness_percentage "$FLAKINESS_PERCENTAGE" \
                                --arg first_appearance_timestamp "$FIRST_SEEN_TIMESTAMP" \
                                '{
                                  "test_name": $test_name,
                                  "is_flaky": $is_flaky,
                                  "is_consistently_failing": $is_consistently_failing,
                                  "flakiness_detection_count": ($flakiness_detection_count | tonumber),
                                  "last_flaky_timestamp": $last_flaky_timestamp,
                                  "consecutive_failure_run_count": ($consecutive_failure_run_count | tonumber),
                                  "total_retries_attempted": ($total_retries_attempted | tonumber),
                                  "total_test_appearances": ($total_test_appearances | tonumber),
                                  "flakiness_percentage": ($flakiness_percentage | tonumber),
                                  "first_appearance_timestamp": $first_appearance_timestamp
                                }'
            )
            AGGREGATED_TESTS_ARRAY=$(echo "$AGGREGATED_TESTS_ARRAY" "$TEST_AGGREGATED_OBJECT" | jq -s '.[0] + [.[1]]')
          done # End of unique test names loop

          # Final output: write the aggregated data to a JSON file.
          echo "$AGGREGATED_TESTS_ARRAY" | jq . > "$ANALYSIS_OUTPUT_FILE"
          echo "Analysis results saved to: '$ANALYSIS_OUTPUT_FILE'"

          echo "total_unique_flaky_tests=$TOTAL_UNIQUE_FLAKY_TESTS" >> "$GITHUB_OUTPUT"
          echo "total_unique_consistent_failures=$TOTAL_UNIQUE_CONSISTENT_FAILURES" >> "$GITHUB_OUTPUT"
          echo "analysis_output_file=$ANALYSIS_OUTPUT_FILE" >> "$GITHUB_OUTPUT"
          echo "Data analysis and aggregation process completed."


      - name: Generate human-readable summary report in Markdown
        id: generate_report
        run: |
          echo "--- Generating human-readable summary report in Markdown format ---"
          ANALYSIS_FILE="${{ steps.analyze_data.outputs.analysis_output_file }}"
          REPORT_FILE="./flaky_test_summary_report.md"
          
          if [ ! -f "$ANALYSIS_FILE" ]; then
            echo "Critical Error: Analysis file '$ANALYSIS_FILE' not found. Cannot generate report."
            exit 1
          fi
          echo "Analysis file '$ANALYSIS_FILE' found. Proceeding with report generation."

          # Extract and sort data for the report sections.
          # Sort flaky tests by flakiness count (descending) and then by test name.
          FLAKY_TESTS_DATA=$(jq -c '.[] | select(.is_flaky == true)' "$ANALYSIS_FILE" | \
                            jq -s 'sort_by(.flakiness_detection_count, .test_name) | reverse | .[]')
          
          # Sort consistently failing tests by consecutive failure count (descending) and then by test name.
          CONSISTENT_FAILURES_DATA=$(jq -c '.[] | select(.is_consistently_failing == true)' "$ANALYSIS_FILE" | \
                                    jq -s 'sort_by(.consecutive_failure_run_count, .test_name) | reverse | .[]')
          
          ALL_TESTS_COUNT=$(jq 'length' "$ANALYSIS_FILE")
          TOTAL_UNIQUE_FLAKY_COUNT=$(echo "$FLAKY_TESTS_DATA" | jq -s 'length')
          TOTAL_UNIQUE_CONSISTENT_FAILURES_COUNT=$(echo "$CONSISTENT_FAILURES_DATA" | jq -s 'length')
          TOTAL_WORKFLOW_RUNS_COLLECTED="${{ needs.collect_flaky_run_data.outputs.total_runs_collected }}"
          COLLECTION_STRATEGY="${{ needs.collect_flaky_run_data.outputs.collection_strategy }}"
          LOOK_BACK_INFO=""

          if [ "$COLLECTION_STRATEGY" == "historical_lookup" ]; then
            LOOK_BACK_DAYS="${{ github.event.inputs.days_to_look_back || 7 }}"
            LOOK_BACK_BRANCH="${{ github.event.inputs.target_branch || 'main' }}"
            LOOK_BACK_INFO=" (over the last ${LOOK_BACK_DAYS} days on branch \`${LOOK_BACK_BRANCH}\`)"
          elif [ "$COLLECTION_STRATEGY" == "single_workflow_run" ]; then
            WORKFLOW_RUN_ID="${{ github.event.workflow_run.id }}"
            WORKFLOW_RUN_BRANCH="${{ github.event.workflow_run.head_branch }}"
            LOOK_BACK_INFO=" (from workflow run \`#${WORKFLOW_RUN_ID}\` on branch \`${WORKFLOW_RUN_BRANCH}\`)"
          fi

          # Start writing the comprehensive Markdown report.
          {
            echo "# Flaky Test Summary Report"
            echo ""
            echo "Generated: $(date -u +%Y-%m-%dT%H:%M:%SZ) UTC"
            echo "Analyzed **$TOTAL_WORKFLOW_RUNS_COLLECTED** workflow runs$LOOK_BACK_INFO."
            echo ""
            echo "---"
            echo ""
            echo "## Overview of Test Suite Stability"
            echo ""
            echo "- **Total Unique Tests Tracked:** \`$ALL_TESTS_COUNT\`"
            echo "- **Unique Flaky Tests Detected:** \`$TOTAL_UNIQUE_FLAKY_COUNT\`"
            echo "- **Unique Consistently Failing Tests:** \`$TOTAL_UNIQUE_CONSISTENT_FAILURES_COUNT\`"
            echo ""
            echo "---"
            echo ""

            if [ "$TOTAL_UNIQUE_FLAKY_COUNT" -gt 0 ]; then
              echo "## âš¡ Flaky Tests (Passed on Retry)"
              echo "The following tests have exhibited flakiness, meaning they failed at least once initially but successfully passed after retries. These tests are intermittent and require investigation into race conditions, environment dependencies, or test isolation issues to ensure deterministic outcomes."
              echo ""
              echo "| Test Name | Flakiness Count | Last Flaky (UTC) | Total Retries | Flakiness % | First Seen (UTC) |"
              echo "|---|---|---|---|---|---|"
              echo "$FLAKY_TESTS_DATA" | jq -r '
                [
                  .test_name,
                  (.flakiness_detection_count | tostring),
                  .last_flaky_timestamp,
                  (.total_retries_attempted | tostring),
                  (.flakiness_percentage | tostring),
                  .first_appearance_timestamp
                ] | @tsv
              ' | while IFS=$'\t' read -r name count last_flaky retries percent first_seen; do
                echo "| \`$name\` | $count | \`$last_flaky\` | $retries | **$(printf "%.2f%%" "$percent")** | \`$first_seen\` |"
              done
              echo ""
              echo "---"
              echo ""
            else
              echo "## ðŸŽ‰ No Flaky Tests Detected!"
              echo "Currently, no tests were identified as flaky (passing on retry) in the analyzed period. This indicates a stable testing environment or a well-behaved test suite."
              echo ""
              echo "---"
              echo ""
            fi

            if [ "$TOTAL_UNIQUE_CONSISTENT_FAILURES_COUNT" -gt 0 ]; then
              echo "## âŒ Consistently Failing Tests (Failed after all retries)"
              echo "These tests failed consistently, even after multiple retries. They represent stable failures that require immediate attention as they are likely blocking functionalities or indicating critical bugs."
              echo ""
              echo "| Test Name | Consecutive Failure Runs | Total Retries Attempted | First Seen (UTC) |"
              echo "|---|---|---|---|"
              echo "$CONSISTENT_FAILURES_DATA" | jq -r '
                [
                  .test_name,
                  (.consecutive_failure_run_count | tostring),
                  (.total_retries_attempted | tostring),
                  .first_appearance_timestamp
                ] | @tsv
              ' | while IFS=$'\t' read -r name count retries first_seen; do
                echo "| \`$name\` | **$count** | $retries | \`$first_seen\` |"
              done
              echo ""
              echo "---"
              echo ""
            else
              echo "## âœ… No Consistently Failing Tests Detected!"
              echo "All reported failures eventually passed or were isolated to flaky behavior, with no consistently failing tests identified during this analysis."
              echo ""
              echo "---"
              echo ""
            fi

            echo "## ðŸ’¡ Actionable Insights & Recommendations"
            echo ""
            if [ "$TOTAL_UNIQUE_FLAKY_COUNT" -gt 0 ]; then
              echo "- **Investigate Flakiness Source:** Prioritize deep dives into the top flaky tests. Look for potential causes such as:"
              echo "  - Resource contention (e.g., database locks, shared file system access)."
              echo "  - Asynchronous operations with inadequate waiting mechanisms."
              echo "  - Time-sensitive assertions or reliance on system clock."
              echo "  - Environment inconsistencies (e.g., specific test runner versions, OS settings)."
              echo "  - Data setup/teardown issues leading to state leakage between tests."
              echo "- **Improve Test Isolation:** Ensure each test runs in a clean, isolated environment to prevent side effects from previous tests."
              echo "- **Refine Retry Strategy:** Evaluate if the current retry mechanism in the `Rerun Flaky Tests` workflow is optimal (e.g., adding exponential back-off)."
              echo "- **Consider Test Quarantine:** For severely flaky tests, temporarily quarantine them from the main test run to unblock CI/CD, while a dedicated team investigates."
              echo "- **Introduce Flakiness Metrics:** Track flakiness over time (e.g., flakiness percentage trends) to identify degradation or improvements."
            else
              echo "- **Maintain Vigilance:** Even without current flakiness, continue monitoring. Regular test suite maintenance is crucial."
              echo "- **Expand Flakiness Detection:** As the test suite grows, consider enhancing the `Rerun Flaky Tests` workflow to detect new types of flakiness."
            fi
            
            if [ "$TOTAL_UNIQUE_CONSISTENT_FAILURES_COUNT" -gt 0 ]; then
              echo "- **Immediate Priority for Stable Failures:** Address consistently failing tests without delay. These are indicators of critical bugs or broken functionality in the codebase."
              echo "- **Alerting Mechanism:** Ensure robust alerting is in place for new consistent failures to notify relevant teams immediately."
            fi
            
            echo "- **Integrate with Dashboards:** For better visibility and historical tracking, consider pushing this summary data to an observability dashboard (e.g., Grafana, custom internal dashboard)."
            echo "- **Automate Issue Creation:** For high-priority flaky or consistently failing tests, automate the creation of tasks or bugs in your issue tracking system (e.g., Jira, GitHub Issues)."
            echo ""
            echo "---"
            echo ""
            echo "_This report is automatically generated by the 'Flaky Test Summary Generator' GitHub Actions workflow. For full details and historical runs, refer to the workflow run artifacts._"
            echo ""

          } > "$REPORT_FILE" # Redirect all output to the Markdown report file

          echo "Summary report successfully generated and saved at: '$REPORT_FILE'."
          echo "summary_report_path=$REPORT_FILE" >> "$GITHUB_OUTPUT"
          echo "total_unique_flaky_tests=$TOTAL_UNIQUE_FLAKY_COUNT" >> "$GITHUB_OUTPUT"
          echo "total_unique_consistent_failures=$TOTAL_UNIQUE_CONSISTENT_FAILURES_COUNT" >> "$GITHUB_OUTPUT"
          echo "Report generation phase completed."

      - name: Upload summary report as an artifact
        uses: actions/upload-artifact@v4
        with:
          name: flaky-test-summary-report
          path: ${{ steps.generate_report.outputs.summary_report_path }}
          retention-days: 14 # Keep the summary report artifact for 14 days
          if-no-files-found: error
        continue-on-error: true # Allow subsequent jobs to proceed even if artifact upload fails
        run: |
          echo "Attempting to upload the generated summary report artifact."
          echo "Artifact path: '${{ steps.generate_report.outputs.summary_report_path }}'"
          echo "Artifact name: 'flaky-test-summary-report'"
          if [ ! -f "${{ steps.generate_report.outputs.summary_report_path }}" ]; then
            echo "Warning: No summary report file found at specified path. Artifact upload will report no files."
          else
            echo "Summary report file exists. Proceeding with artifact upload."
          fi
          echo "Artifact upload process initiated, check summary for status."

  notify_channels:
    runs-on: ubuntu-latest
    needs: analyze_and_generate_summary # This job depends on a successful analysis and summary report generation
    if: success() && (needs.analyze_and_generate_summary.outputs.total_unique_flaky_tests_count > 0 || needs.analyze_and_generate_summary.outputs.total_unique_consistent_failures_count > 0) # Only notify if issues are detected

    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Required for GitHub API interactions (e.g., issue comments)

    steps:
      - name: Checkout repository (for any notification scripts or config)
        uses: actions/checkout@v4

      - name: Use Node.js 22 (for any JS-based notification clients or utilities)
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Download summary report artifact for notification
        uses: actions/download-artifact@v4
        with:
          name: flaky-test-summary-report
          path: ./downloaded_report/
        env:
          ACTIONS_STEP_DEBUG: true
        run: |
          echo "Attempting to download artifact 'flaky-test-summary-report' to './downloaded_report/'."
          if [ -d "./downloaded_report/flaky-test-summary-report" ]; then
            mv ./downloaded_report/flaky-test-summary-report/* ./downloaded_report/
            echo "Artifact downloaded and contents moved to './downloaded_report/'."
          else
            echo "Error: Downloaded artifact directory not found. Check artifact upload in previous job."
            exit 1
          fi
          echo "Listing contents of ./downloaded_report/ after download:"
          ls -l ./downloaded_report/

      - name: Read summary report content for notifications
        id: read_report
        run: |
          REPORT_FILE="./downloaded_report/${{ needs.analyze_and_generate_summary.outputs.summary_report_path | split('/') | last }}"
          if [ ! -f "$REPORT_FILE" ]; then
            echo "Error: Summary report file '$REPORT_FILE' not found for notification. Skipping further notification steps."
            exit 1
          fi
          
          # Read the full report content. For multi-line string outputs in GitHub Actions,
          # it's best practice to base64 encode it, especially for complex Markdown.
          REPORT_CONTENT=$(cat "$REPORT_FILE")
          ENCODED_REPORT_CONTENT=$(echo "$REPORT_CONTENT" | base64 -w 0) # -w 0 for no line wrapping
          
          echo "Summary report content successfully read and base64 encoded for safe transfer."
          echo "report_content_base64=$ENCODED_REPORT_CONTENT" >> "$GITHUB_OUTPUT"
          
          # Also output a truncated preview for easier debugging in workflow logs.
          # Escape double quotes for JSON context and replace newlines with spaces for single-line output.
          REPORT_PREVIEW=$(echo "$REPORT_CONTENT" | head -n 5 | sed 's/"/\\"/g' | tr '\n' ' ')
          echo "report_truncated_preview=$REPORT_PREVIEW" >> "$GITHUB_OUTPUT"
          echo "Report content read successfully for notification payloads."

      - name: Get Short SHA and Workflow Run URL for context
        id: get_context
        run: |
          SHORT_SHA=$(echo "${{ github.sha }}" | cut -c 1-7)
          WORKFLOW_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "short_sha=$SHORT_SHA" >> "$GITHUB_OUTPUT"
          echo "workflow_run_url=$WORKFLOW_RUN_URL" >> "$GITHUB_OUTPUT"
          echo "Context variables (Short SHA, Workflow Run URL) prepared."

      - name: Prepare Slack message payload (simulated)
        id: prepare_slack_message
        env:
          REPORT_CONTENT_BASE64: ${{ steps.read_report.outputs.report_content_base64 }}
          TOTAL_FLAKY_TESTS: ${{ needs.analyze_and_generate_summary.outputs.total_unique_flaky_tests_count }}
          TOTAL_CONSISTENT_FAILURES: ${{ needs.analyze_and_generate_summary.outputs.total_unique_consistent_failures_count }}
          SHORT_SHA: ${{ steps.get_context.outputs.short_sha }}
          WORKFLOW_RUN_URL: ${{ steps.get_context.outputs.workflow_run_url }}
        run: |
          echo "--- Preparing Slack notification message payload ---"
          # Decode the report content from base64.
          REPORT_CONTENT=$(echo "$REPORT_CONTENT_BASE64" | base64 --decode)
          
          SLACK_TITLE=":rotating_light: *Flaky Test Summary Report - \`${{ github.ref_name }}@$SHORT_SHA\`*"
          
          SUMMARY_BLOCK=""
          if [ "$TOTAL_FLAKY_TESTS" -gt 0 ]; then
            SUMMARY_BLOCK+="- *Total Unique Flaky Tests Detected:* \`$TOTAL_FLAKY_TESTS\`\n"
          fi
          if [ "$TOTAL_CONSISTENT_FAILURES" -gt 0 ]; then
            SUMMARY_BLOCK+="- *Total Unique Consistently Failing Tests Detected:* \`$TOTAL_CONSISTENT_FAILURES\`\n"
          fi
          
          MESSAGE_TEXT="Please review the latest report for your test suite. Full report available as an artifact."
          if [ "$TOTAL_FLAKY_TESTS" -eq 0 ] && [ "$TOTAL_CONSISTENT_FAILURES" -eq 0 ]; then
             MESSAGE_TEXT="ðŸ¥³ No new flaky or consistently failing tests detected in the latest analysis. Keep up the good work!"
             SLACK_TITLE=":white_check_mark: *Flaky Test Summary - Stable!*"
          fi

          # Construct a simplified Slack message for demonstration.
          # A real Slack integration would use `slackapi/slack-action` with more complex block kit messages.
          SLACK_FULL_MESSAGE=$(cat <<EOF
          $SLACK_TITLE
          $MESSAGE_TEXT
          $SUMMARY_BLOCK
          :link: *Workflow Run:* <$WORKFLOW_RUN_URL|View Run Details>
          :memo: *Full Report Artifact:* <$WORKFLOW_RUN_URL/artifacts|Download Report>
          \`\`\`markdown
          $(echo "$REPORT_CONTENT" | head -n 25) # Truncate for Slack message body
          ... (view full report for complete details)
          \`\`\`
EOF
          )
          
          # Output the prepared message (escaped for single-line GitHub Action output).
          # For a proper Slack action, you'd output specific JSON for Block Kit.
          echo "slack_message_payload=$(echo "$SLACK_FULL_MESSAGE" | sed 's/"/\\"/g' | tr '\n' ' ')" >> "$GITHUB_OUTPUT"
          echo "Slack message payload preparation complete. Preview below."
          echo "--- Slack Message Preview ---"
          echo "$SLACK_FULL_MESSAGE" | head -n 30
          echo "---------------------------"

      - name: Send Slack Notification (simulated action)
        # Use an external action like `slackapi/slack-action@v1.2.4` for real notifications.
        # Example configuration for a real scenario:
        # uses: slackapi/slack-action@v1.2.4
        # with:
        #   channel-id: '#flaky-test-alerts'
        #   slack-message: "${{ steps.prepare_slack_message.outputs.slack_message_payload }}"
        # env:
        #   SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        if: success() # Only attempt if previous steps were successful
        # And if a Slack webhook/bot token is available (commented out for simulation)
        # && secrets.SLACK_BOT_TOKEN
        run: |
          echo "--- Sending simulated Slack notification ---"
          echo "If a 'slackapi/slack-action' were configured, a notification would now be sent to the designated channel."
          echo "The following message (or a structured Block Kit equivalent) would be dispatched:"
          echo "${{ steps.prepare_slack_message.outputs.slack_message_payload }}"
          echo "Ensure 'SLACK_BOT_TOKEN' is set as a secret and 'channel-id' is configured for actual integration."
          echo "----------------------------------------"
          
      - name: Post Summary to GitHub Issue/Comment (simulated action)
        # Use an external action like `peter-evans/create-or-update-issue-comment@v4` for real comments.
        # Or `peter-evans/create-issue@v4` for new issues.
        # Example configuration for a real scenario:
        # uses: peter-evans/create-or-update-issue-comment@v4
        # with:
        #   issue-number: 123 # Or use `github.event.pull_request.number` for PR comments
        #   body: "${{ steps.read_report.outputs.report_content_base64 }}"
        #   token: ${{ secrets.GITHUB_TOKEN }}
        if: success()
        env:
          REPORT_CONTENT_BASE64: ${{ steps.read_report.outputs.report_content_base64 }}
          TOTAL_FLAKY_TESTS: ${{ needs.analyze_and_generate_summary.outputs.total_unique_flaky_tests_count }}
          TOTAL_CONSISTENT_FAILURES: ${{ needs.analyze_and_generate_summary.outputs.total_unique_consistent_failures_count }}
          SHORT_SHA: ${{ steps.get_context.outputs.short_sha }}
          WORKFLOW_RUN_URL: ${{ steps.get_context.outputs.workflow_run_url }}
          AGGREGATED_DATA_FILE: ${{ needs.analyze_and_generate_summary.outputs.analysis_output_file }}
        run: |
          echo "--- Preparing GitHub Issue/Comment notification ---"
          REPORT_CONTENT=$(echo "$REPORT_CONTENT_BASE64" | base64 --decode)
          
          # Determine the appropriate title and introductory message based on the findings.
          GITHUB_TITLE_PREFIX="Flaky Test Summary Report"
          if [ "$TOTAL_FLAKY_TESTS" -eq 0 ] && [ "$TOTAL_CONSISTENT_FAILURES" -eq 0 ]; then
            GITHUB_TITLE_PREFIX="Flaky Test Status - All Clear"
          elif [ "$TOTAL_FLAKY_TESTS" -gt 0 ]; then
            GITHUB_TITLE_PREFIX="Flaky Test Alert: New/Existing Flakiness Detected"
          elif [ "$TOTAL_CONSISTENT_FAILURES" -gt 0 ]; then
            GITHUB_TITLE_PREFIX="Critical Failure Alert: Consistently Failing Tests"
          fi
          
          ISSUE_OR_COMMENT_TITLE="$GITHUB_TITLE_PREFIX - \`${{ github.ref_name }}@$SHORT_SHA\`"
          
          # Construct the body for a GitHub Issue or PR comment.
          GITHUB_BODY=$(cat <<EOF
          # $ISSUE_OR_COMMENT_TITLE
          
          This is an automated report on the stability of your test suite.
          
          **Summary:**
          - Total unique flaky tests detected: **$TOTAL_FLAKY_TESTS**
          - Total unique consistently failing tests: **$TOTAL_CONSISTENT_FAILURES**
          
          :link: **Workflow Run:** [View Run Details]($WORKFLOW_RUN_URL)
          :memo: **Full Report Artifact:** [Download Report]($WORKFLOW_RUN_URL/artifacts)
          
          \`\`\`markdown
          $(echo "$REPORT_CONTENT")
          \`\`\`
          
          _This comment/issue was generated by the 'Flaky Test Summary Generator' workflow._
EOF
          )
          
          echo "GitHub Issue/Comment payload preparation complete. Preview below."
          echo "--- GitHub Issue/Comment Body Preview (truncated) ---"
          echo "$GITHUB_BODY" | head -n 40 # Truncate for log display
          echo "..."
          echo "-----------------------------------------------------"

          # Conditional logic for actual GitHub interaction:
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "Context: Workflow triggered by Pull Request. Would typically post a comment to PR #${{ github.event.pull_request.number }}."
            echo "Mock command: gh pr comment ${{ github.event.pull_request.number }} --body \"$GITHUB_BODY\""
          elif [ "$TOTAL_FLAKY_TESTS" -gt 5 ] || [ "$TOTAL_CONSISTENT_FAILURES" -gt 2 ]; then
            echo "High volume of issues detected. Recommending creation of a new GitHub Issue for tracking."
            echo "Mock command: gh issue create --title \"$ISSUE_OR_COMMENT_TITLE\" --body \"$GITHUB_BODY\""
          elif [ "$TOTAL_FLAKY_TESTS" -gt 0 ] || [ "$TOTAL_CONSISTENT_FAILURES" -gt 0 ]; then
            echo "Some issues detected. Recommending updating an existing tracking issue or creating a new one if none exists."
            echo "Mock command: gh issue comment <existing-issue-number> --body \"$GITHUB_BODY\""
          else
            echo "No significant issues detected. No GitHub Issue/Comment action recommended at this time."
          fi
          echo "GitHub notification simulation completed."

      - name: Integrate with external dashboard/metrics system (simulated)
        if: success()
        env:
          TOTAL_FLAKY_TESTS: ${{ needs.analyze_and_generate_summary.outputs.total_unique_flaky_tests_count }}
          TOTAL_CONSISTENT_FAILURES: ${{ needs.analyze_and_generate_summary.outputs.total_unique_consistent_failures_count }}
          TOTAL_WORKFLOW_RUNS_COLLECTED: ${{ needs.collect_flaky_run_data.outputs.total_runs_collected }}
          ANALYSIS_OUTPUT_FILE: ${{ needs.analyze_and_generate_summary.outputs.analysis_output_file }}
        run: |
          echo "--- Simulating integration with an external observability dashboard or metrics system ---"
          echo "This step is designed to export key metrics and detailed analysis data in a machine-readable format."
          echo "Common destinations include: Prometheus, Grafana, Datadog, or custom internal dashboards."
          
          # Read the full analysis results to potentially send more granular data.
          ANALYSIS_JSON_CONTENT=$(cat "./downloaded_report/${AGGREGATED_DATA_FILE | split('/') | last}")

          # Construct a JSON payload that contains summarized and potentially granular data.
          DASHBOARD_METRICS_PAYLOAD=$(jq -n \
                                      --arg total_flaky "$TOTAL_FLAKY_TESTS" \
                                      --arg total_consistent_failures "$TOTAL_CONSISTENT_FAILURES" \
                                      --arg runs_processed "$TOTAL_WORKFLOW_RUNS_COLLECTED" \
                                      --arg run_id "${{ github.run_id }}" \
                                      --arg repo "${{ github.repository }}" \
                                      --arg branch "${{ github.ref_name }}" \
                                      --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
                                      --argjson detailed_analysis "$ANALYSIS_JSON_CONTENT" \
                                      '{
                                        "metrics": {
                                          "flaky_tests.total_unique_count": ($total_flaky | tonumber),
                                          "flaky_tests.consistent_failures_total_count": ($total_consistent_failures | tonumber),
                                          "flaky_tests.workflow_runs_processed": ($runs_processed | tonumber),
                                          "flaky_tests.dashboard_update_timestamp": $timestamp
                                        },
                                        "metadata": {
                                          "workflow_run_id": ($run_id | tonumber),
                                          "repository": $repo,
                                          "branch": $branch,
                                          "trigger_event": "${{ github.event_name }}",
                                          "dashboard_report_url": "${{ steps.get_context.outputs.workflow_run_url }}"
                                        },
                                        "detailed_analysis_snapshot": $detailed_analysis
                                      }'
          )
          
          echo "--- Simulated JSON payload to be sent to external dashboard API ---"
          echo "$DASHBOARD_METRICS_PAYLOAD" | jq .
          echo "------------------------------------------------------------------"
          
          echo "--- Example cURL command for a hypothetical dashboard API endpoint ---"
          # In a real scenario, this would involve a dedicated action or a `curl` command.
          echo "curl -X POST -H \"Content-Type: application/json\" \\"
          echo "     -H \"Authorization: Bearer \$DASHBOARD_API_KEY\" \\"
          echo "     -d '$DASHBOARD_METRICS_PAYLOAD' \\"
          echo "     \"https://your-dashboard-api.com/metrics/flaky-test-status\""
          echo "--------------------------------------------------------------------"
          echo "External dashboard integration simulation completed. Ensure API keys and endpoints are configured."

      - name: Workflow Completion Message
        run: |
          echo "=========================================================="
          echo " Flaky Test Summary Generator workflow completed successfully!"
          echo " Reports generated and notifications processed (simulated)."
          echo " Check the workflow summary for artifacts and outputs."
          echo " Thank you for helping keep the test suite healthy! :heart:"
          echo "=========================================================="
