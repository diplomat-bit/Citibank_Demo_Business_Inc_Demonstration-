name: Config Linter

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  lint_configs:
    runs-on: ubuntu-latest

    # The strategy matrix is kept for consistency with the seed file,
    # though most linters here are language-agnostic or Python-based.
    # It allows for future expansion with Node.js-specific linters.
    strategy:
      matrix:
        node-version: [ 22 ]

    steps:
    - uses: actions/checkout@v4
      with:
        # Fetch full history for tools like Gitleaks that scan commit history
        fetch-depth: 0

    - name: Use Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}

    - name: Install Linting Tools
      # This step installs all necessary command-line interface (CLI) tools for linting.
      # The chosen tools cover various configuration file formats, infrastructure-as-code (IaC) types,
      # and general best practices. Each tool is installed using its recommended method
      # (pip for Python, apt for system packages, curl for direct binary downloads, npm for Node.js).
      run: |
        echo "========================================================"
        echo "## Installing essential linting tools for configuration analysis ##"
        echo "========================================================"

        # 1. System package updates and Python (for pip, Checkov, yamllint via pip if needed)
        # Ensure the package list is up-to-date and Python3 and pip are available.
        # These are foundational for many security and linting tools.
        echo "  Updating apt packages and installing Python3/pip..."
        sudo apt-get update -y
        sudo apt-get install -y python3 python3-pip apt-transport-https ca-certificates curl gnupg lsb-release
        echo "  Python3 and pip installed."

        # 2. yamllint: A highly configurable linter for YAML files.
        # It helps enforce best practices, coding styles, and detects common syntax errors or inconsistencies
        # in YAML documents, which are prevalent in configuration, CI/CD, and IaC.
        echo "  Installing yamllint..."
        sudo apt-get install -y yamllint
        if ! command -v yamllint &> /dev/null; then
            echo "    yamllint not found via apt, attempting installation via pip..."
            pip3 install yamllint
        fi
        echo "  yamllint installed successfully."

        # 3. jq: A lightweight and flexible command-line JSON processor.
        # This tool is indispensable for parsing, filtering, and manipulating JSON data in shell scripts.
        # It's used here for performing custom, semantic checks on JSON configuration files,
        # ensuring values meet specific criteria beyond just syntax.
        echo "  Installing jq (JSON processor)..."
        sudo apt-get install -y jq
        echo "  jq installed successfully."

        # 4. shellcheck: A static analysis tool specifically designed for shell scripts.
        # It helps developers find bugs, identify bad practices, and discover potential security vulnerabilities
        # in Bash, Dash, and other POSIX shell scripts often used in CI/CD or deployment.
        echo "  Installing shellcheck (for shell scripts)..."
        sudo apt-get install -y shellcheck
        echo "  shellcheck installed successfully."

        # 5. jsonlint: A simple command-line validator primarily for JSON syntax.
        # It's useful for quick checks to ensure JSON files are well-formed and syntactically correct
        # before any deeper, semantic analysis is performed with tools like `jq`.
        echo "  Installing jsonlint (via npm for basic JSON syntax validation)..."
        npm install -g jsonlint
        echo "  jsonlint installed successfully."

        # 6. Hadolint: A smarter Dockerfile linter that helps you build best practice Docker images.
        # It parses the Dockerfile and warns about common issues, security flaws (e.g., outdated base images,
        # exposed sensitive information), and adherence to Docker best practices.
        echo "  Installing Hadolint (Dockerfile linter)..."
        HADOLINT_VERSION="2.12.0" # Specify version for consistency and reproducibility
        wget -q -O /tmp/hadolint "https://github.com/hadolint/hadolint/releases/download/v${HADOLINT_VERSION}/hadolint-Linux-x86_64"
        sudo mv /tmp/hadolint /usr/local/bin/hadolint
        sudo chmod +x /usr/local/bin/hadolint
        echo "  Hadolint v${HADOLINT_VERSION} installed successfully."

        # 7. Checkov: A comprehensive static analysis tool for Infrastructure-as-Code (IaC).
        # It's used to detect security and compliance misconfigurations in various IaC types,
        # including Terraform, CloudFormation, Kubernetes, ARM Templates, Serverless framework, and Dockerfile.
        # Crucial for shifting left on security in cloud infrastructure.
        echo "  Installing Checkov (IaC security & compliance scanner)..."
        pip3 install checkov
        # Optional: For expanded capabilities, specific framework dependencies can be installed
        # pip3 install "checkov[terraform]"
        echo "  Checkov installed successfully."

        # 8. tfsec: A specialized security scanner for Terraform code.
        # tfsec focuses specifically on Terraform to identify potential misconfigurations and
        # security vulnerabilities, providing a deeper analysis than general IaC scanners for Terraform.
        echo "  Installing tfsec (Terraform security scanner)..."
        curl -s https://raw.githubusercontent.com/aquasecurity/tfsec/master/scripts/install_linux.sh | sudo bash
        echo "  tfsec installed successfully."

        # 9. kube-linter: A static analysis tool specifically designed for Kubernetes YAML files.
        # It ensures that Kubernetes manifests (deployments, services, ingress, etc.) adhere to
        # best practices for security, reliability, and efficiency, reducing common misconfigurations.
        echo "  Installing kube-linter (Kubernetes YAML linter)..."
        KUBELINTER_VERSION="0.6.1" # Specify version for consistency
        curl -sL "https://github.com/stackrox/kube-linter/releases/download/v${KUBELINTER_VERSION}/kube-linter-linux-amd64" -o /usr/local/bin/kube-linter
        sudo chmod +x /usr/local/bin/kube-linter
        echo "  kube-linter v${KUBELINTER_VERSION} installed successfully."

        # 10. Gitleaks: A fast, all-in-one solution for detecting hardcoded secrets in git repos.
        # It scans commit history and current files for sensitive information like API keys,
        # tokens, and passwords, preventing accidental exposure and improving security posture.
        echo "  Installing Gitleaks (secret detection tool)..."
        GITLEAKS_VERSION="8.18.0" # Current stable version
        curl -sL "https://github.com/zricethezav/gitleaks/releases/download/v${GITLEAKS_VERSION}/gitleaks_${GITLEAKS_VERSION}_linux_x64.tar.gz" | sudo tar -xz -C /usr/local/bin gitleaks
        sudo chmod +x /usr/local/bin/gitleaks
        echo "  Gitleaks v${GITLEAKS_VERSION} installed successfully."

        echo "All specified linting tools installed successfully."
        echo "========================================================"

    - name: Lint Configuration Files
      # This step orchestrates the comprehensive linting process for various types of configuration files
      # using the tools installed in the previous step. It categorizes checks by file type and linter,
      # provides detailed output for each check, and maintains an overall pass/fail status for the workflow.
      run: |
        # Initialize a flag to track overall linting failure. If any check fails, this will be set to 1.
        LINT_FAILED=0
        echo "Starting comprehensive configuration file linting across the repository..."
        echo "=========================================================================="

        # Define common exclude paths for `find` commands to avoid scanning build artifacts,
        # dependency directories, and version control metadata.
        EXCLUDE_PATHS="-path "./.git" -prune -o -path "./node_modules" -prune -o -path "./vendor" -prune -o -path "./tmp" -prune -o -path "./build" -prune -o -path "./dist" -prune -o -path "./.terraform" -prune -o"

        # =================================================================================
        # SECTION 1: YAML Configuration File Linting (yamllint)
        # Checks for syntax errors, stylistic issues, and adherence to best practices in YAML files.
        # =================================================================================
        echo "## 1. Linting YAML files with yamllint (syntax, style, best practices) ##"
        echo "Searching for YAML files in common configuration, deployment, and workflow paths..."

        # Define common directories where YAML files are typically found.
        COMMON_YAML_DIRS=(
          "." # Include current directory for root-level configs
          "config" "configs" "configuration"
          "deploy" "deployment" "deployments"
          "kubernetes" "k8s" "manifests"
          "helm" "charts"
          "ci" ".github/workflows" ".github/PULL_REQUEST_TEMPLATE"
          "infrastructure" "environments"
          "swagger" "openapi" # For API definitions
        )

        # Build a list of all relevant YAML files, filtering out excluded paths.
        YAML_FILE_PATTERNS="-name "*.yaml" -o -name "*.yml""
        ALL_YAML_FILES_RAW=""
        for dir in "${COMMON_YAML_DIRS[@]}"; do
          if [ -d "$dir" ]; then
            FOUND_FILES=$(find "$dir" $EXCLUDE_PATHS \( $YAML_FILE_PATTERNS \) -type f -print 2>/dev/null)
            if [ -n "$FOUND_FILES" ]; then
              ALL_YAML_FILES_RAW+="$FOUND_FILES\n"
            fi
          fi
        done

        # Deduplicate the list of files to avoid redundant scans.
        readarray -t UNIQUE_YAML_FILES <<< "$(echo -e "$ALL_YAML_FILES_RAW" | sort -u)"

        if [ ${#UNIQUE_YAML_FILES[@]} -gt 0 ]; then
          echo "  Found ${#UNIQUE_YAML_FILES[@]} unique YAML files. Proceeding with yamllint."
          # Prioritize a project-specific .yamllint.yaml config, then a global one in .github/linters, otherwise use default rules.
          YAML_CONFIG_FILE_PARAM=""
          if [ -f ".yamllint.yaml" ]; then
            YAML_CONFIG_FILE_PARAM="-c .yamllint.yaml"
            echo "  Using project-specific yamllint config: .yamllint.yaml"
          elif [ -f ".github/linters/.yamllint.yaml" ]; then
            YAML_CONFIG_FILE_PARAM="-c .github/linters/.yamllint.yaml"
            echo "  Using shared yamllint config: .github/linters/.yamllint.yaml"
          else
            echo "  No custom yamllint config found, running with default rules."
          fi

          YAML_LINT_STATUS=0
          # Iterate through each unique YAML file for individual reporting.
          for yaml_file in "${UNIQUE_YAML_FILES[@]}"; do
            if [ -f "$yaml_file" ]; then # Double-check file existence
              echo "    Linting: $yaml_file"
              if ! yamllint $YAML_CONFIG_FILE_PARAM "$yaml_file"; then
                echo "    YAML linting FAILED for $yaml_file!"
                YAML_LINT_STATUS=1
              fi
            fi
          done

          if [ "$YAML_LINT_STATUS" -ne 0 ]; then
            echo "  Overall YAML linting FAILED for one or more files."
            LINT_FAILED=1
          else
            echo "  Overall YAML linting PASSED for all specified files."
          fi
        else
          echo "  No YAML files found for linting in specified directories."
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # SECTION 2: JSON Configuration File Linting (jsonlint & jq for semantic checks)
        # Covers basic syntax validation and advanced semantic checks for JSON files.
        # =================================================================================
        echo "## 2. Linting JSON files with jsonlint and custom jq checks ##"
        echo "Searching for JSON files in common configuration, source, and data paths..."

        # Define common directories where JSON files might be located.
        COMMON_JSON_DIRS=(
          "." # Current directory
          "config" "configs" "src" "frontend/src" "backend/src"
          "data" "schemas" ".github" "project" "swagger" "openapi"
          "assets" "templates"
        )
        JSON_FILE_PATTERNS="-name "*.json""

        ALL_JSON_FILES_RAW=""
        for dir in "${COMMON_JSON_DIRS[@]}"; do
          if [ -d "$dir" ]; then
            FOUND_FILES=$(find "$dir" $EXCLUDE_PATHS \( $JSON_FILE_PATTERNS \) -type f -print 2>/dev/null)
            if [ -n "$FOUND_FILES" ]; then
              ALL_JSON_FILES_RAW+="$FOUND_FILES\n"
            fi
          fi
        done
        readarray -t UNIQUE_JSON_FILES <<< "$(echo -e "$ALL_JSON_FILES_RAW" | sort -u)"

        if [ ${#UNIQUE_JSON_FILES[@]} -gt 0 ]; then
          echo "  Found ${#UNIQUE_JSON_FILES[@]} unique JSON files. Proceeding with linting."
          JSON_LINT_STATUS=0

          # 2.1: Basic JSON Syntax Validation with jsonlint
          echo "  Performing basic JSON syntax validation with jsonlint..."
          # `xargs -r` ensures `jsonlint` is not run if no files are passed.
          if ! printf '%s\n' "${UNIQUE_JSON_FILES[@]}" | xargs -r jsonlint -q; then
            echo "  JSON syntax validation FAILED for one or more files!"
            JSON_LINT_STATUS=1
          else
            echo "  JSON syntax validation PASSED for all files."
          fi

          # 2.2: Advanced Semantic Checks with jq
          # These checks look for specific content, structure, or best practices within known JSON file types.
          echo "  Performing advanced semantic JSON checks with jq for specific file types..."
          JQ_CHECK_FAILED=0

          # Iterate through each unique JSON file for specific content checks.
          for json_file in "${UNIQUE_JSON_FILES[@]}"; do
            echo "    Checking: $json_file"

            case "$json_file" in
              # --- package.json checks (Node.js project metadata and dependencies) ---
              *package.json)
                echo "      Running specific checks for package.json..."
                if ! jq -e '.name | type == "string" and length > 0' "$json_file" > /dev/null; then echo "        Error: '$json_file': 'name' field is missing or invalid." && JQ_CHECK_FAILED=1; fi
                if ! jq -e '.version | type == "string" and length > 0' "$json_file" > /dev/null; then echo "        Error: '$json_file': 'version' field is missing or invalid." && JQ_CHECK_FAILED=1; fi
                if ! jq -e '.main | type == "string" and length > 0' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'main' field missing. Consider adding for module entry point." && JQ_CHECK_FAILED=1; fi
                if jq -e '.private == false' "$json_file" > /dev/null && ! jq -e '.license | type == "string" and length > 0' "$json_file" > /dev/null; then echo "        Error: '$json_file' is public but 'license' field is missing. Important for open source projects." && JQ_CHECK_FAILED=1; fi
                if ! jq -e 'has("scripts")' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'scripts' section missing. Common build/test commands might be absent." && JQ_CHECK_FAILED=1; fi
                if ! jq -e '.scripts.test | type == "string"' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'test' script is missing. Essential for automated testing." && JQ_CHECK_FAILED=1; fi
                if jq -e '.dependencies | has("eslint") or has("prettier") or has("typescript")' "$json_file" > /dev/null; then echo "        Warning: '$json_file': Development tools like 'eslint', 'prettier', 'typescript' found in 'dependencies'. They should typically be in 'devDependencies'." && JQ_CHECK_FAILED=1; fi
                ;;
              # --- tsconfig.json checks (TypeScript compiler configuration) ---
              *tsconfig.json)
                echo "      Running specific checks for tsconfig.json..."
                if ! jq -e '.compilerOptions.strict == true' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'strict' compiler option is not true. Enable strict mode for better type safety and code quality." && JQ_CHECK_FAILED=1; fi
                if ! jq -e '.compilerOptions.noImplicitAny == true' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'noImplicitAny' is not true. Enable for better type inference and error prevention." && JQ_CHECK_FAILED=1; fi
                if ! jq -e '.compilerOptions.esModuleInterop == true' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'esModuleInterop' is not true. Can cause module resolution issues with CommonJS/ES Modules interop." && JQ_CHECK_FAILED=1; fi
                if ! jq -e '.compilerOptions.target | IN("es2018", "es2019", "es2020", "es2021", "es2022", "esnext", "ESNext")' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'target' compiler option is old. Consider updating to a modern ES version for better features/performance." && JQ_CHECK_FAILED=1; fi
                ;;
              # --- .eslintrc.json checks (ESLint configuration for JavaScript/TypeScript) ---
              *.eslintrc.json)
                echo "      Running specific checks for .eslintrc.json..."
                if ! jq -e '.extends | contains(["eslint:recommended"])' "$json_file" > /dev/null; then echo "        Warning: '$json_file': does not extend 'eslint:recommended'. Basic linting rules might be missing." && JQ_CHECK_FAILED=1; fi
                if ! jq -e '.env.node == true or .env.browser == true or .env.es2020 == true or .env.es2021 == true or .env.es2022 == true' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'env' is missing or not set for common environments (node/browser/es versions). Global variables might not be recognized." && JQ_CHECK_FAILED=1; fi
                if ! jq -e 'has("parserOptions.ecmaVersion")' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'parserOptions.ecmaVersion' is missing. Recommended for modern JS features." && JQ_CHECK_FAILED=1; fi
                ;;
              # --- config/database.json, secrets.json, credentials.json (sensitive configuration) ---
              *config/database.json|*secrets.json|*credentials.json)
                echo "      Running specific checks for sensitive JSON files (database, secrets, credentials)..."
                # Generic check for hardcoded sensitive strings (e.g., "password", "secret", "key")
                if jq -e 'walk(if type == "string" then strings | test("(?i)password|secret|key=[A-Za-z0-9+/=]{20,}|token=[A-Za-z0-9-_\\.]{30,}") else . end)' "$json_file" > /dev/null; then
                  echo "        Error: '$json_file' potentially contains hardcoded sensitive information (password, secret, API key, token). Use environment variables or secure storage mechanisms!"
                  JQ_CHECK_FAILED=1
                fi
                if jq -e '.connection_string | contains("root")' "$json_file" > /dev/null; then echo "        Warning: '$json_file': Connection string uses 'root' user. Avoid using root for application database access." && JQ_CHECK_FAILED=1; fi
                ;;
              # --- Generic API configuration checks (e.g., config/api.json, app.json) ---
              *config/api.json|*config/app.json)
                echo "      Running specific checks for API/application configuration files..."
                if ! jq -e '.api_version | type == "string" and length > 0' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'api_version' field is missing or invalid. Important for API compatibility." && JQ_CHECK_FAILED=1; fi
                if jq -e '.debug_mode == true or .environment == "development"' "$json_file" > /dev/null; then echo "        Warning: '$json_file': Debug mode is enabled or environment is set to 'development'. Ensure this is not deployed to production environments." && JQ_CHECK_FAILED=1; fi
                ;;
              # --- Firebase configuration files (firebase.json) ---
              *firebase.json)
                echo "      Running specific checks for Firebase configuration files..."
                if ! jq -e '.hosting.public | type == "string" and length > 0' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'hosting.public' directory is not defined. Public assets might not be served correctly." && JQ_CHECK_FAILED=1; fi
                if jq -e '.hosting.rewrites | length == 0' "$json_file" > /dev/null; then echo "        Warning: '$json_file': 'hosting.rewrites' is empty. No custom routing or SPA fallback defined." && JQ_CHECK_FAILED=1; fi
                ;;
              # --- CloudFormation template checks (common in IaC) ---
              *cloudformation/*.json|*cfn/*.json|*template*.json)
                echo "      Running specific checks for CloudFormation JSON templates..."
                if ! jq -e '.AWSTemplateFormatVersion | type == "string"' "$json_file" > /dev/null; then echo "        Error: '$json_file': Missing 'AWSTemplateFormatVersion'." && JQ_CHECK_FAILED=1; fi
                if ! jq -e 'has("Resources")' "$json_file" > /dev/null; then echo "        Error: '$json_file': CloudFormation template has no 'Resources' section." && JQ_CHECK_FAILED=1; fi
                ;;
              *)
                # No specific semantic checks defined for this JSON file type,
                # basic syntax validation was already performed.
                ;;
            esac
          done

          if [ "$JQ_CHECK_FAILED" -ne 0 ]; then
            echo "  Advanced JSON semantic checks FAILED for one or more files."
            JSON_LINT_STATUS=1
          else
            echo "  Advanced JSON semantic checks PASSED for all specified files."
          fi

          if [ "$JSON_LINT_STATUS" -ne 0 ]; then
            LINT_FAILED=1
          fi
        else
          echo "  No JSON files found for linting in specified directories."
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # SECTION 3: Dockerfile Linting (hadolint)
        # Enforces Dockerfile best practices, identifies security vulnerabilities,
        # and promotes maintainable Docker images.
        # =================================================================================
        echo "## 3. Linting Dockerfiles with Hadolint ##"
        echo "Searching for Dockerfiles in the repository..."

        DOCKERFILE_FILE_PATTERNS="-name "Dockerfile" -o -name "Dockerfile.*""
        ALL_DOCKERFILES=$(find . $EXCLUDE_PATHS \( $DOCKERFILE_FILE_PATTERNS \) -type f -print 2>/dev/null)
        readarray -t UNIQUE_DOCKERFILES <<< "$(echo -e "$ALL_DOCKERFILES" | sort -u)"

        if [ ${#UNIQUE_DOCKERFILES[@]} -gt 0 ]; then
          echo "  Found ${#UNIQUE_DOCKERFILES[@]} unique Dockerfiles. Running Hadolint..."
          # Hadolint can accept a custom configuration file (.hadolint.yaml) to customize rules.
          HADOLINT_CONFIG_PARAM=""
          if [ -f ".hadolint.yaml" ]; then
            HADOLINT_CONFIG_PARAM="--config .hadolint.yaml"
            echo "  Using project-specific Hadolint config: .hadolint.yaml"
          elif [ -f ".github/linters/.hadolint.yaml" ]; then
            HADOLINT_CONFIG_PARAM="--config .github/linters/.hadolint.yaml"
            echo "  Using shared Hadolint config: .github/linters/.hadolint.yaml"
          fi

          DOCKERFILE_LINT_STATUS=0
          for dockerfile in "${UNIQUE_DOCKERFILES[@]}"; do
            echo "    Linting: $dockerfile"
            if ! hadolint $HADOLINT_CONFIG_PARAM "$dockerfile"; then
              echo "    Dockerfile linting FAILED for $dockerfile!"
              DOCKERFILE_LINT_STATUS=1
            fi
          done

          if [ "$DOCKERFILE_LINT_STATUS" -ne 0 ]; then
            echo "  Overall Dockerfile linting FAILED for one or more files."
            LINT_FAILED=1
          else
            echo "  Overall Dockerfile linting PASSED for all specified files."
          fi
        else
          echo "  No Dockerfiles found for linting."
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # SECTION 4: Shell Script Linting (shellcheck)
        # Analyzes shell scripts for common errors, bad practices, and potential security issues.
        # =================================================================================
        echo "## 4. Linting Shell Scripts with Shellcheck ##"
        echo "Searching for shell scripts (files ending in .sh) and scripts with shebangs..."

        # Find all .sh files that are not in excluded paths.
        ALL_SHELL_SCRIPTS=$(find . $EXCLUDE_PATHS -name "*.sh" -type f -print 2>/dev/null)

        # Additionally, one might want to extract and lint shell blocks from YAML files (e.g., GitHub Actions 'run' steps).
        # This is more complex and typically requires a dedicated tool or custom script to extract code blocks.
        # For simplicity, this workflow primarily focuses on standalone .sh files.
        # Example to find YAML files containing shebangs for manual review:
        # SHEBANG_YAML_FILES=$(grep -rlE '#!/(bin/bash|bin/sh)' . --include "*.y?ml" --exclude-dir=".git" --exclude-dir="node_modules" --exclude-dir="vendor" 2>/dev/null)
        # if [ -n "$SHEBANG_YAML_FILES" ]; then
        #   echo "  Found YAML files containing shell shebangs: ${SHEBANG_YAML_FILES}. Consider reviewing embedded scripts manually."
        # fi

        readarray -t UNIQUE_SHELL_SCRIPTS <<< "$(echo -e "$ALL_SHELL_SCRIPTS" | sort -u)"

        if [ ${#UNIQUE_SHELL_SCRIPTS[@]} -gt 0 ]; then
          echo "  Found ${#UNIQUE_SHELL_SCRIPTS[@]} unique shell scripts. Running shellcheck..."
          SHELLCHECK_LINT_STATUS=0
          for script_file in "${UNIQUE_SHELL_SCRIPTS[@]}"; do
            echo "    Linting: $script_file"
            # shellcheck can be configured to ignore specific rules using comments within the script (e.g., '# shellcheck disable=SCxxxx').
            if ! shellcheck "$script_file"; then
              echo "    Shell script linting FAILED for $script_file!"
              SHELLCHECK_LINT_STATUS=1
            fi
          done

          if [ "$SHELLCHECK_LINT_STATUS" -ne 0 ]; then
            echo "  Overall Shell script linting FAILED for one or more files."
            LINT_FAILED=1
          else
            echo "  Overall Shell script linting PASSED for all specified files."
          fi
        else
          echo "  No standalone shell scripts (.sh files) found for linting."
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # SECTION 5: Infrastructure as Code (IaC) Security Linting (Checkov)
        # Scans a wide range of IaC configurations for security and compliance misconfigurations.
        # Provides broad coverage for various cloud providers and IaC tools.
        # =================================================================================
        echo "## 5. Linting IaC configurations with Checkov (security & compliance) ##"
        echo "Running Checkov across the repository for various IaC types..."

        # Define common IaC directories to focus the scan. This can make the scan more efficient
        # if the repository has specific IaC subdirectories, or scan '.' for everything.
        COMMON_IAC_DIRS=(
          "." # Scan entire repo as a fallback or for root-level IaC
          "terraform" "tf" "infrastructure/terraform"
          "cloudformation" "cfn" "infrastructure/cloudformation"
          "kubernetes" "k8s" "manifests" "helm" "charts"
          "serverless" "sls" "lambda"
          "azure-pipelines" "cicd/azure"
          "aws-config" "gcp-config" "azure-config"
          "arm-templates" "bicep"
        )
        CHECK_DIRS_PARAM=""
        for dir in "${COMMON_IAC_DIRS[@]}"; do
          if [ -d "$dir" ]; then
            CHECK_DIRS_PARAM+=" --directory $dir"
          fi
        done

        if [ -n "$CHECK_DIRS_PARAM" ]; then
          echo "  Checkov scanning directories: $CHECK_DIRS_PARAM"
          # Checkov exit codes: 0 = no misconfigurations, 1 = execution error, 2 = misconfigurations found.
          # We treat exit code 2 as a failure for the workflow.
          # --compact: Reduces output verbosity. --output cli: Standard console output.
          # --output-file: Saves results to a JSON file for programmatic access and detailed reporting.
          # --skip-framework secrets: Avoids scanning for generic secrets which might be handled by other dedicated tools (like Gitleaks).
          # --framework all: Scans across all supported frameworks. Alternatively, specify:
          #   --framework terraform --framework kubernetes --framework dockerfile --framework serverless ...
          set +e # Temporarily disable exit on error for checkov to handle its own exit codes gracefully.
          checkov $CHECK_DIRS_PARAM --framework all --compact --output cli --quiet --output-file checkov_results.json --skip-framework secrets
          CHECKOV_EXIT_CODE=$?
          set -e # Re-enable exit on error

          if [ "$CHECKOV_EXIT_CODE" -eq 0 ]; then
            echo "  Checkov scan PASSED: No misconfigurations found."
          elif [ "$CHECKOV_EXIT_CODE" -eq 2 ]; then
            echo "  Checkov scan FAILED: Misconfigurations found. See checkov_results.json for detailed output."
            LINT_FAILED=1
          else
            echo "  Checkov scan FAILED with exit code $CHECKOV_EXIT_CODE (possibly an error in tool execution or invalid input)."
            LINT_FAILED=1
          fi

          # Detailed reporting from checkov_results.json if the file exists.
          if [ -f "checkov_results.json" ]; then
            echo "  Processing Checkov results from checkov_results.json for summary..."
            CRITICAL_COUNT=$(jq '.results.failed_checks | map(select(.severity == "CRITICAL")) | length' checkov_results.json)
            HIGH_COUNT=$(jq '.results.failed_checks | map(select(.severity == "HIGH")) | length' checkov_results.json)
            MEDIUM_COUNT=$(jq '.results.failed_checks | map(select(.severity == "MEDIUM")) | length' checkov_results.json)
            LOW_COUNT=$(jq '.results.failed_checks | map(select(.severity == "LOW")) | length' checkov_results.json)
            PASSED_COUNT=$(jq '.results.passed_checks | length' checkov_results.json)
            SKIPPED_COUNT=$(jq '.results.skipped_checks | length' checkov_results.json)

            echo "  Checkov Summary of findings:"
            echo "    Critical Failures Detected: $CRITICAL_COUNT"
            echo "    High Severity Failures:     $HIGH_COUNT"
            echo "    Medium Severity Failures:   $MEDIUM_COUNT"
            echo "    Low Severity Failures:      $LOW_COUNT"
            echo "    Passed Checks:              $PASSED_COUNT"
            echo "    Skipped Checks:             $SKIPPED_COUNT"

            if [ "$CRITICAL_COUNT" -gt 0 ] || [ "$HIGH_COUNT" -gt 0 ]; then
              echo "  CRITICAL or HIGH severity Checkov failures detected. Immediate attention recommended."
              LINT_FAILED=1 # Re-confirm workflow failure for critical/high issues.
            fi
          fi
        else
          echo "  No common IaC directories found for Checkov scan (e.g., 'terraform', 'kubernetes', 'cloudformation'). Skipping."
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # SECTION 6: Terraform Security Linting (tfsec)
        # A dedicated security scanner for Terraform code, providing granular insights
        # into potential misconfigurations and security vulnerabilities specific to Terraform.
        # =================================================================================
        echo "## 6. Linting Terraform configurations with tfsec ##"
        echo "Searching for Terraform configuration directories and files..."

        # Find directories that contain .tf files, as tfsec typically scans directories.
        TERRAFORM_DIRS_RAW=$(find . $EXCLUDE_PATHS -type d -name "terraform" -o -type d -path "*/tf" -o -type f -name "*.tf" -exec dirname {} \; -print 2>/dev/null)
        readarray -t UNIQUE_TERRAFORM_DIRS <<< "$(echo -e "$TERRAFORM_DIRS_RAW" | sort -u)"

        if [ ${#UNIQUE_TERRAFORM_DIRS[@]} -gt 0 ]; then
          echo "  Found ${#UNIQUE_TERRAFORM_DIRS[@]} unique Terraform paths. Running tfsec..."
          TFSEC_LINT_STATUS=0
          # tfsec can be given multiple paths. We'll pass them all at once for efficiency.
          # Use printf '%q ' to correctly handle paths with spaces if they were present.
          TFSEC_COMMAND_ARGS=$(printf '%q ' "${UNIQUE_TERRAFORM_DIRS[@]}")

          echo "  Executing tfsec $TFSEC_COMMAND_ARGS"
          if ! tfsec $TFSEC_COMMAND_ARGS; then
            echo "  tfsec scan FAILED for one or more Terraform configurations!"
            TFSEC_LINT_STATUS=1
          else
            echo "  tfsec scan PASSED for all specified Terraform configurations."
          fi

          if [ "$TFSEC_LINT_STATUS" -ne 0 ]; then
            echo "  Overall tfsec linting FAILED."
            LINT_FAILED=1
          fi
        else
          echo "  No Terraform directories or .tf files found for tfsec scan."
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # SECTION 7: Kubernetes YAML Linting (kube-linter)
        # Validates Kubernetes manifests against best practices for security, reliability,
        # and resource efficiency, helping to prevent common misconfigurations.
        # =================================================================================
        echo "## 7. Linting Kubernetes YAML files with kube-linter ##"
        echo "Searching for Kubernetes YAML files and directories..."

        # Define specific patterns for common Kubernetes manifest files.
        K8S_FILE_PATTERNS="-name "*k8s*.yaml" -o -name "*k8s*.yml" -o -name "*deployment*.yaml" -o -name "*service*.yaml" -o -name "*ingress*.yaml" -o -name "*configmap*.yaml" -o -name "*secret*.yaml" -o -name "*pvc*.yaml" -o -name "*pod*.yaml" -o -name "*daemonset*.yaml" -o -name "*statefulset*.yaml" -o -name "*hpa*.yaml" -o -name "*cronjob*.yaml""

        # Find specific Kubernetes directories (e.g., 'kubernetes/', 'k8s/', 'manifests/').
        K8S_DIRS=$(find . -type d \( -name "kubernetes" -o -name "k8s" -o -name "manifests" -o -name "helm/charts" \) $EXCLUDE_PATHS -print 2>/dev/null)
        readarray -t UNIQUE_K8S_DIRS <<< "$(echo -e "$K8S_DIRS" | sort -u)"

        # Find individual Kubernetes YAML files that might not be in a recognized directory.
        K8S_INDIVIDUAL_FILES=$(find . $EXCLUDE_PATHS \( $K8S_FILE_PATTERNS \) -type f -print 2>/dev/null)
        readarray -t UNIQUE_K8S_FILES <<< "$(echo -e "$K8S_INDIVIDUAL_FILES" | sort -u)"

        # Combine and deduplicate all found Kubernetes targets (directories and files).
        ALL_K8S_TARGETS=()
        for dir in "${UNIQUE_K8S_DIRS[@]}"; do ALL_K8S_TARGETS+=("$dir"); done
        for file in "${UNIQUE_K8S_FILES[@]}"; do ALL_K8S_TARGETS+=("$file"); done
        readarray -t DEDUPED_K8S_TARGETS <<< "$(printf "%s\n" "${ALL_K8S_TARGETS[@]}" | sort -u)"

        if [ ${#DEDUPED_K8S_TARGETS[@]} -gt 0 ]; then
          echo "  Found ${#DEDUPED_K8S_TARGETS[@]} unique Kubernetes files/directories. Running kube-linter..."
          KUBELINTER_LINT_STATUS=0
          # kube-linter can accept multiple files/directories as arguments.
          # Prioritize a project-specific .kube-linter.yaml config.
          KUBELINTER_CONFIG_PARAM=""
          if [ -f ".kube-linter.yaml" ]; then
            KUBELINTER_CONFIG_PARAM="--config .kube-linter.yaml"
            echo "  Using project-specific kube-linter config: .kube-linter.yaml"
          elif [ -f ".github/linters/.kube-linter.yaml" ]; then
            KUBELINTER_CONFIG_PARAM="--config .github/linters/.kube-linter.yaml"
            echo "  Using shared kube-linter config: .github/linters/.kube-linter.yaml"
          fi

          # Construct the command, quoting arguments for paths that might contain spaces.
          KUBELINTER_COMMAND="kube-linter lint $KUBELINTER_CONFIG_PARAM $(printf '%q ' "${DEDUPED_K8S_TARGETS[@]}")"
          echo "  Executing: $KUBELINTER_COMMAND"
          eval "$KUBELINTER_COMMAND" # `eval` is used here because `printf '%q '` creates quoted strings that need evaluation.
          if [ $? -ne 0 ]; then
            echo "  Overall kube-linter FAILED for one or more Kubernetes configurations!"
            KUBELINTER_LINT_STATUS=1
          else
            echo "  Overall kube-linter PASSED for all specified Kubernetes configurations."
          fi

          if [ "$KUBELINTER_LINT_STATUS" -ne 0 ]; then
            LINT_FAILED=1
          fi
        else
          echo "  No Kubernetes YAML files or specific directories found for linting."
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # SECTION 8: Secret Detection (Gitleaks)
        # Scans the entire repository (including git history) for hardcoded secrets,
        # preventing accidental exposure of sensitive credentials.
        # =================================================================================
        echo "## 8. Detecting Hardcoded Secrets with Gitleaks ##"
        echo "Running Gitleaks to scan the repository (including history) for sensitive information..."

        # Define Gitleaks configuration file (optional, for custom rules or ignoring specific patterns).
        GITLEAKS_CONFIG_PARAM=""
        if [ -f ".gitleaks.toml" ]; then
          GITLEAKS_CONFIG_PARAM="--config=.gitleaks.toml"
          echo "  Using project-specific Gitleaks config: .gitleaks.toml"
        elif [ -f ".github/linters/.gitleaks.toml" ]; then
          GITLEAKS_CONFIG_PARAM="--config=.github/linters/.gitleaks.toml"
          echo "  Using shared Gitleaks config: .github/linters/.gitleaks.toml"
        fi

        # Run Gitleaks. It scans the entire repository by default (--source=.).
        # --report-format=json and --report-path: Saves detailed findings to a JSON file.
        # --redact: Hides sensitive values in the console output and report for security.
        # Gitleaks exit code is 0 if no secrets are found, 1 if secrets are detected.
        echo "  Scanning the entire repository (current state and history) for secrets..."
        set +e # Temporarily disable exit on error to handle Gitleaks' specific exit code for findings.
        gitleaks detect --source=. --report-format=json --report-path=gitleaks_results.json --redact $GITLEAKS_CONFIG_PARAM
        GITLEAKS_EXIT_CODE=$?
        set -e # Re-enable exit on error

        if [ "$GITLEAKS_EXIT_CODE" -eq 0 ]; then
          echo "  Gitleaks scan PASSED. No secrets detected."
        elif [ "$GITLEAKS_EXIT_CODE" -eq 1 ]; then
          echo "  Gitleaks detected SECRETS in the repository!"
          # Attempt to parse the JSON report to provide a summary of findings.
          if [ -f "gitleaks_results.json" ]; then
            SECRET_COUNT=$(jq 'length' gitleaks_results.json)
            echo "  Found $SECRET_COUNT potential secrets. Review gitleaks_results.json for details (values are redacted in output)."
          else
            echo "  Gitleaks report file 'gitleaks_results.json' not found. Check Gitleaks execution for errors."
          fi
          LINT_FAILED=1
        else
          echo "  Gitleaks scan FAILED with exit code $GITLEAKS_EXIT_CODE (unexpected error during execution)."
          LINT_FAILED=1
        fi
        echo "--------------------------------------------------------------------------"


        # =================================================================================
        # FINAL STATUS CHECK
        # Summarizes the overall outcome of all linting tasks and determines workflow status.
        # =================================================================================
        echo "=========================================================================="
        if [ "$LINT_FAILED" -eq 1 ]; then
          echo "One or more configuration file linting or security checks FAILED."
          echo "Please review the logs above for detailed error messages and suggested fixes."
          exit 1 # Exit with a non-zero code to indicate workflow failure.
        else
          echo "All specified configuration files passed linting and security checks."
          echo "The repository adheres to established configuration best practices."
        fi
        echo "=========================================================================="